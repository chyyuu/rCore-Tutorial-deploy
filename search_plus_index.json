{"./":{"url":"./","title":"实验简介","keywords":"","body":"rCore-Tutorial V3（开发中） 本教学仓库是继 rCore_tutorial V2 后重构的 V3 版本。 本文档的目标主要针对「做实验的同学」，我们会对每章结束后提供完成的代码，你的练习题只需要基于我们给出的版本上增量实现即可，不需要重新按照教程写一遍。 而对想完整实现一个 rCore 的同学来说，我们的文档可能不太友好。因为在开发过程中，我们需要对清晰和全面做很多的权衡和考虑、需要省略掉大量语法层面而 OS 无关的代码来带来更多的可读性和精简性，所以想参考本文档并完整实现同学可能不会有从头复制到尾的流畅（这样的做法也不是学习的初衷），可能需要自己有一些完整的认识和思考。 另外，如果你觉得字体大小和样式不舒服，可以通过 GitBook 上方的按钮调节。 仓库目录 docs/：教学实验指导分实验内容和开发规范 notes/：开题报告和若干讨论 os/：操作系统代码 user/：用户态代码 SUMMARY.md：GitBook 目录页 book.json：GitBook 配置文件 rust-toolchain：限定 Rust 工具链版本 deploy.sh：自动部署脚本 实验指导 基于 GitBook，目前已经部署到了 GitHub Pages 上面。 文档本地使用方法 npm install -g gitbook-cli gitbook install gitbook serve 代码 操作系统代码 本项目基于 cargo 和 make 等工具，在根目录通过 make run 命令即可运行代码，更具体的细节请参见 Makefile、os/Makefile 以及 user/Makefile。 参考和感谢 本文档和代码部分参考了： rCore zCore rCore_tutorial V2 使用Rust编写操作系统 在此对仓库的开发和维护者表示感谢，同时也感谢很多在本项目开发中一起讨论和勘误的老师和同学们。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/pre-lab/env.html":{"url":"docs/pre-lab/env.html","title":"环境部署","keywords":"","body":"环境部署 在开展实验之前，我们需要根据不同的平台提前安装相关依赖的软件包，具体需要的软件包如下： Rust 工具链 Rust 版本管理工具：rustup Rust 软件包管理工具：cargo Rust 编译器：rustc 等等 虚拟机软件：QEMU （版本至少支持 RISC-V 64） 具体安装的方法在不同平台上安装方式类似，但也有细微差别，后面会有具体说明。 安装 QEMU 根据不同平台，我们分为下面 2 个部分来介绍。 macOS 在 macOS 中，我们可以直接打开命令行用 Homebrew 软件包管理器来安装最新版 QEMU 和其依赖： 运行命令 brew install qemu Linux / Windows WSL 在 Linux 中，由于很多软件包管理器的默认软件源中包含的 QEMU 版本过低，这里推荐的方式是我们自己手动从源码编译安装： 运行命令 # 下载源码包 （如果下载速度过慢可以把地址替换为我们提供的地址：TODO） wget https://download.qemu.org/qemu-4.2.0.tar.xz # 解压 tar xvJf qemu-4.2.0.tar.xz # 编译安装并配置 RISC-V 支持 cd qemu-4.2.0 ./configure --target-list=riscv32-softmmu,riscv64-softmmu make -j$(nproc) sudo make install 如果在运行 configure 时遇到软件包依赖的问题（以 Ubuntu 系统举例）： 出现 ERROR: pkg-config binary 'pkg-config' not found 时，可以通过 sudo apt-get install pkg-config 安装； 出现 ERROR: glib-2.48 gthread-2.0 is required to compile QEMU 时，可以通过 sudo apt-get install libglib2.0-dev 安装； 出现 ERROR: pixman >= 0.21.8 not present 时，可以通过 sudo apt-get install libpixman-1-dev 安装。 如果有其他问题，请针对不同操作系统在软件包管理器中查找并安装依赖。 当然如果你可以找到包含较新版本的 QEMU 的软件包源，也可以通过软件包管理器直接安装： 运行命令 # Ubuntu / Debian / Windows WSL sudo apt-get install qemu # CentOS / Fedora / RedHat / SUSE sudo yum install qemu 完成后 安装完成后可以用 qemu-system-riscv64 --version 命令检查是否成功安装我们需要的 RISC-V 64 虚拟器。 安装 Rust 工具链 首先安装 Rust 版本管理器 rustup 和 Rust 包管理器 cargo，这里我们用官方的安装脚本来安装： 运行命令 curl https://sh.rustup.rs -sSf | sh 如果通过官方的脚本下载失败了，可以在浏览器的地址栏中输入 https://sh.rustup.rs 来下载脚本，在本地运行即可。 如果官方的脚本在运行时出现了网络速度较慢的问题，可选地可以通过修改 rustup 的镜像地址（修改为中国科学技术大学的镜像服务器）来加速： 运行命令 export RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static export RUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup curl https://sh.rustup.rs -sSf | sh 或者也可以通过在运行前设置命令行中的科学上网代理来实现： 运行命令 # e.g. Shadowsocks 代理 export https_proxy=http://127.0.0.1:1080 export http_proxy=http://127.0.0.1:1080 export ftp_proxy=http://127.0.0.1:1080 安装完成后，最好我们也可以把软件包管理器 cargo 所用的软件包镜像地址 crates.io 也换成中国科学技术大学的镜像服务器来加速。我们打开（如果没有就新建）~/.cargo/config 文件，并把内容修改为： ~/.cargo/config [source.crates-io] registry = \"https://github.com/rust-lang/crates.io-index\" replace-with = 'ustc' [source.ustc] registry = \"git://mirrors.ustc.edu.cn/crates.io-index\" 安装完成后 在相关软件包安装完成之后，只需要下面的命令，就可以把整个教程完成之后的 rCore 系统在你的系统上运行起来： 运行命令 # 克隆仓库并编译运行 git clone TODO cd rCore-Tutorial git checkout master # 编译运行 make run 如果一切正常，则 QEMU 模拟的 RISC-V 64 处理器将输出 运行输出 TODO 需要说明的是，Rust 包含 stable、beta 和 nightly 三个版本。默认情况下我们安装的是 stable 稳定版。由于在编写操作系统时需要使用 Rust 的一些不稳定的实验功能，因此我们使用 nightly 每日构建版。 但是，由于官方不保证 nightly 版本的 ABI 稳定性，也就意味着今天写的代码用未来的 nightly 可能无法编译通过，因此一般在使用 nightly 时应该锁定一个日期。 所以我们的工作目录下会有一个名为 rust-toolchain 的文件（无后缀名），在其中有所需的工具链版本： rust-toolchain nightly-2020-06-27 在第一次编译项目时，rustup 会自动去下载对应版本的工具链。今后所有在这个目录或其子目录下使用 Rust 时都会自动切换到这个版本的工具链。随着日后的更新，后面的日期可能会变化，请以 GitHub 仓库上的版本为准。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/pre-lab/gdb.html":{"url":"docs/pre-lab/gdb.html","title":"GDB 调试方法*","keywords":"","body":"使用 GDB 对 rCore 进行 debug* *：使用 GDB 调试可以方便观察 rCore 运行过程，但不属于教程要求 GDB 需要支持 riscv64 架构才能够对 rCore 进行 debug。 运行 gdb --configuration 来查看本地的 GDB 支持什么架构，其中 --target 参数指定了它可以 debug 的架构 如果 gdb 不支持，可以按照下面的步骤来安装 riscv64-unknown-elf-gdb 安装 riscv64-unknown-elf-gdb 安装依赖（针对 Linux，macOS 可以遇到错误再去搜索） python 并非必须 在 Ubuntu 20.04 等系统中，python 和 python-dev 需要替换成 python2 和 python2-devsudo apt-get install libncurses5-dev python python-dev texinfo libreadline-dev 前往清华镜像下载最新的 GDB 源代码 解压源代码，并定位到目录 执行以下命令 --prefix 是安装的路径，按照以上指令会安装到 /usr/local/bin/ 下 --with-python 是 python2 的地址，它和 --enable-tui 都是为了支持后续安装一个可视化插件，并非必须mkdir build cd build ../configure --prefix=/usr/local --with-python=/usr/bin/python --target=riscv64-unknown-elf --enable-tui=yes 编译安装 # Linux make -j$(nproc) # macOS make -j$(sysctl -n hw.ncpu) sudo make install （可选）安装 gdb-dashboard 插件，优化 debug 体验 wget -P ~ https://git.io/.gdbinit 使用 GDB 对 rCore 进行 debug 在 os/Makefile 中，包含了 debug 方法，可以执行 make debug 来在 tmux 中开启调试。 手动： 将 QEMU 的运行参数加上 -s -S，它将在 1234 端口等待调试器接入 运行 riscv64-unknown-elf-gdb 在 GDB 中执行 file target/riscv64imac-unknown-none-elf/debug/os 来加载未被 strip 过的内核文件中的各种符号 在 GDB 中执行 target remote localhost:1234 来连接 QEMU，开始调试 GDB 简单使用方法 控制流 b 在函数进入时设置断点，例如 b rust_main 或 b os::memory::heap::init cont 继续执行 n 执行下一行代码，不进入函数 ni 执行下一条指令（跳转指令则执行至返回） s 执行下一行代码，进入函数 si 执行下一条指令，包括跳转指令 查看状态 如果没有安装 gdb-dashboard，可以通过 layout 指令来呈现寄存器等信息，具体查看 help layout 使用 x/ 来查看内存，例如 x/8i 0x80200000 表示查看 0x80200000 起始的 8 条指令。具体格式查看 help x 注意 调试虚实地址转换时，GDB 完全通过读取文件来判断函数地址，因此可能会遇到一些问题，需要手动设置地址来调试 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/intro.html":{"url":"docs/lab-0/guide/intro.html","title":"摘要","keywords":"","body":"实验指导零 实验概要 这一章的实验指导中，你将会学到： 使用 Rust 包管理器 cargo 创建一个 Rust 项目 移除 Rust 程序对操作系统的依赖，构建一个独立化可执行的程序 我们将程序的目标平台设置为 RISC-V，这样我们的代码将可以在 RISC-V 指令集的裸机（Bare Metal）上执行 Rust 代码 生成内核镜像、调整代码的内存布局并在 QEMU 模拟器中启动 封装如输出、关机等一些 SBI 的接口，方便后续开发 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-1.html":{"url":"docs/lab-0/guide/part-1.html","title":"创建项目","keywords":"","body":"创建 Rust 项目 创建项目 我们首先创建一个整个项目的目录，并在工作目录中首先创建一个名为 rust-toolchain 的文件，并在其中写入所需要的工具链版本： rust-toolchain nightly-2020-06-27 之后在目录内部使用 cargo new 命令在我们的项目目录内创建一个新的 Rust 项目 os，命令如下： 运行命令 cargo new os 这里我们把项目命名为 os。同时，cargo 默认为我们添加了 --bin 选项，说明我们将要创建一个可执行文件而非一个库。 目录结构 创建完成后，整个项目的目录结构如下： 目录结构 Project 项目目录 ├── rust-toolchain Rust 工具链版本 └── os ├── Cargo.toml 项目配置文件 └── src 源代码路径 └── main.rs 源程序 构建和运行 接下来我们进入 os 文件夹，并尝试构建、运行项目： 运行输出 $ cargo run ... Hello, world! 打开 os/src/main.rs 发现里面确实只是输出了一行 Hello, world!。这个应用可以正常运行，但是即使只是这么一个简单的功能，也离不开所在操作系统的帮助。我们既然要写一个新的操作系统，就不能依赖于任何已有操作系统，接下来我们尝试移除该项目对于操作系统的依赖。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-2.html":{"url":"docs/lab-0/guide/part-2.html","title":"移除标准库依赖","keywords":"","body":"移除标准库依赖 禁用标准库 项目默认是链接 Rust 标准库 std 的，它依赖于操作系统，因此我们需要显式通过 #![no_std] 将其禁用： os/src/main.rs //! # 全局属性 //! - `#![no_std]` //! 禁用标准库 #![no_std] fn main() { println!(\"Hello, rCore-Tutorial!\"); } 我们使用 cargo build 构建项目，会出现下面的错误： 运行输出 error: cannot find macro `println` in this scope --> src/main.rs:3:5 | 7 | println!(\"Hello, rCore-Tutorial!\"); | ^^^^^^^ error: `#[panic_handler]` function required, but not found error: language item required, but not found: `eh_personality` 接下来，我们依次解决这些问题。 宏 println! 第一个错误是说 println! 宏未找到，实际上这个宏属于 Rust 标准库 std，它会依赖操作系统标准输出等一系列功能。由于它被我们禁用了当然就找不到了。我们暂时将该输出语句删除，之后给出不依赖操作系统的实现。 panic 处理函数 第二个错误是说需要一个函数作为 panic_handler ，这个函数负责在程序发生 panic 时调用。它默认使用标准库 std 中实现的函数并依赖于操作系统特殊的文件描述符，由于我们禁用了标准库，因此只能自己实现它： os/src/main.rs use core::panic::PanicInfo; /// 当 panic 发生时会调用该函数 /// 我们暂时将它的实现为一个死循环 #[panic_handler] fn panic(_info: &PanicInfo) -> ! { loop {} } [info] Rust Panic Panic 在 Rust 中表明程序遇到了错误，需要被迫停止运行或者通过捕获的机制来处理。 类型为 PanicInfo 的参数包含了 panic 发生的文件名、代码行数和可选的错误信息。这个函数从不返回，所以他被标记为发散函数（Diverging Function）。发散函数的返回类型称作 Never 类型（\"never\" type），记为 !。对这个函数，我们目前能做的很少，所以我们只需编写一个死循环 loop {}。 这里我们用到了核心库 core，与标准库 std 不同，这个库不需要操作系统的支持，下面我们还会与它打交道。 eh_personality 语义项 第三个错误提到了语义项（Language Item） ，它是编译器内部所需的特殊函数或类型。刚才的 panic_handler 也是一个语义项，我们要用它告诉编译器当程序发生 panic 之后如何处理。 而这个错误相关语义项 eh_personality ，其中 eh 是 Exception Handling 的缩写，它是一个标记某函数用来实现堆栈展开处理功能的语义项。这个语义项也与 panic 有关。 [info] 堆栈展开 (Stack Unwinding) 通常当程序出现了异常时，从异常点开始会沿着 caller 调用栈一层一层回溯，直到找到某个函数能够捕获这个异常或终止程序。这个过程称为堆栈展开。 当程序出现异常时，我们需要沿着调用栈一层层回溯上去回收每个 caller 中定义的局部变量（这里的回收包括 C++ 的 RAII 的析构以及 Rust 的 drop 等）避免造成捕获异常并恢复后的内存溢出。 而在 Rust 中，panic 证明程序出现了错误，我们则会对于每个 caller 函数调用依次这个被标记为堆栈展开处理函数的函数进行清理。 这个处理函数是一个依赖于操作系统的复杂过程，在标准库中实现。但是我们禁用了标准库使得编译器找不到该过程的实现函数了。 简单起见，我们这里不会进一步捕获异常也不需要清理现场，我们设置为直接退出程序即可。这样堆栈展开处理函数不会被调用，编译器也就不会去寻找它的实现了。 因此，我们在项目配置文件中直接将 dev 配置和 release 配置的 panic 的处理策略设为直接终止，也就是直接调用我们的 panic_handler 而不是先进行堆栈展开等处理再调用。 os/Cargo.toml ... # panic 时直接终止，因为我们没有实现堆栈展开的功能 [profile.dev] panic = \"abort\" [profile.release] panic = \"abort\" 此时，我们 cargo build ，但是又出现了新的错误，我们将在后面的部分解决： 运行输出 error: requires `start` lang_item var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-3.html":{"url":"docs/lab-0/guide/part-3.html","title":"移除运行时环境依赖","keywords":"","body":"移除运行时环境依赖 运行时系统 对于大多数语言，他们都使用了运行时系统（Runtime System），这可能导致 main 函数并不是实际执行的第一个函数。 以 Rust 语言为例，一个典型的链接了标准库的 Rust 程序会首先跳转到 C 语言运行时环境中的 crt0（C Runtime Zero）进入 C 语言运行时环境设置 C 程序运行所需要的环境（如创建堆栈或设置寄存器参数等）。 然后 C 语言运行时环境会跳转到 Rust 运行时环境的入口点（Entry Point）进入 Rust 运行时入口函数继续设置 Rust 运行环境，而这个 Rust 的运行时入口点就是被 start 语义项标记的。Rust 运行时环境的入口点结束之后才会调用 main 函数进入主程序。 C 语言运行时环境和 Rust 运行时环境都需要标准库支持，我们的程序无法访问。如果覆盖了 start 语义项，仍然需要 crt0，并不能解决问题。所以需要重写覆盖整个 crt0 入口点： os/src/main.rs //! # 全局属性 //! - `#![no_std]` //! 禁用标准库 #![no_std] //! //! - `#![no_main]` //! 不使用 `main` 函数等全部 Rust-level 入口点来作为程序入口 #![no_main] use core::panic::PanicInfo; /// 当 panic 发生时会调用该函数 /// 我们暂时将它的实现为一个死循环 #[panic_handler] fn panic(_info: &PanicInfo) -> ! { loop {} } /// 覆盖 crt0 中的 _start 函数 /// 我们暂时将它的实现为一个死循环 #[no_mangle] pub extern \"C\" fn _start() -> ! { loop {} } 我们加上 #![no_main] 告诉编译器我们不用常规的入口点。 同时我们实现一个 _start 函数来代替 crt0，并加上 #[no_mangle] 告诉编译器对于此函数禁用编译期间的名称重整（Name Mangling），即确保编译器生成一个名为 _start 的函数，而非为了实现函数重载等而生成的形如 _ZN3blog_os4_start7hb173fedf945531caE 散列化后的函数名。由于 _start 是大多数系统的默认入口点名字，所以我们要确保它不会发生变化。 接着，我们使用 extern \"C\" 描述 _start 函数，这是 Rust 中的 FFI （Foreign Function Interface, 语言交互接口）语法，表示此函数是一个 C 函数而非 Rust 函数。由于 _start 是作为 C 语言运行时的入口点，看起来合情合理。 由于程序会一直停在 crt0 的入口点，我们可以移除没用的 main 函数。 链接错误 再次 cargo build ，我们会看到一大段链接错误。 链接器（Linker）是一个程序，它将生成的目标文件组合为一个可执行文件。不同的操作系统如 Windows、macOS 或 Linux，规定了不同的可执行文件格式，因此也各有自己的链接器，抛出不同的错误；但这些错误的根本原因还是相同的：链接器的默认配置假定程序依赖于 C 语言的运行时环境，但我们的程序并不依赖于它。 为了解决这个错误，我们需要告诉链接器，它不应该包含 C 语言运行时环境。我们可以选择提供特定的链接器参数（Linker Argument），也可以选择编译为裸机目标（Bare Metal Target），我们将沿着后者的思路在后面解决这个问题，即直接编译为裸机目标不链接任何运行时环境。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-4.html":{"url":"docs/lab-0/guide/part-4.html","title":"编译为裸机目标","keywords":"","body":"编译为裸机目标 在默认情况下，Rust 尝试适配当前的系统环境，编译可执行程序。举个例子，如果你使用 x86_64 平台的 Windows 系统，Rust 将尝试编译一个扩展名为 .exe 的 Windows 可执行程序，并使用 x86_64 指令集。这个环境又被称作为你的宿主系统（Host System）。 为了描述不同的环境，Rust 使用一个称为目标三元组（Target Triple）的字符串 ---。要查看当前系统的目标三元组，我们可以运行 rustc --version --verbose： 运行输出 rustc 1.46.0-nightly (7750c3d46 2020-06-26) binary: rustc commit-hash: 7750c3d46bc19784adb1ee6e37a5ec7e4cd7e772 commit-date: 2020-06-26 host: x86_64-unknown-linux-gnu release: 1.46.0-nightly LLVM version: 10.0 上面这段输出来自一个 x86_64 平台下的 Linux 系统。我们能看到，host 字段的值为三元组 x86_64-unknown-linux-gnu，它包含了 CPU 架构 x86_64、供应商 unknown、操作系统 linux 和二进制接口 gnu。 Rust 编译器尝试为当前系统的三元组编译，并假定底层有一个类似于 Windows 或 Linux 的操作系统提供 C 语言运行环境，然而这将导致链接器错误。所以，为了避免这个错误，我们可以另选一个底层没有操作系统的运行环境。 这样的运行环境被称作裸机环境，例如目标三元组 riscv64imac-unknown-none-elf 描述了一个 RISC-V 64 位指令集的系统。我们暂时不需要了解它的细节，只需要知道这个环境底层没有操作系统，这是由三元组中的 none 描述的。要为这个目标编译，我们需要使用 rustup 添加它： 运行命令 rustup target add riscv64imac-unknown-none-elf 这行命令将为目标下载一个标准库和 core 库。这之后，我们就能为这个目标成功构建独立式可执行程序了： 运行命令 cargo build --target riscv64imac-unknown-none-elf 编译出的结果被放在了 os/target/riscv64imac-unknown-none-elf/debug 文件夹中。可以看到其中有一个名为 os 的可执行文件。不过由于它的目标平台是 RISC-V 64，我们暂时还不能通过我们的开发环境执行它。 由于我们之后都会使用 RISC-V 作为编译目标，为了避免每次都要加 --target 参数，我们可以使用 cargo 配置文件为项目配置默认的编译选项。 在 os 文件夹中创建一个 .cargo 文件夹，并在其中创建一个名为 config 的文件，在其中填入以下内容： os/.cargo/config # 编译的目标平台 [build] target = \"riscv64imac-unknown-none-elf\" 这指定了此项目编译时默认的目标。以后我们就可以直接使用 cargo build 来编译了。 至此，我们完成了在 RISC-V 64 位平台的二进制程序编译，后面我们将通过布局和代码的简单调整实现一个最简单的内核。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-5.html":{"url":"docs/lab-0/guide/part-5.html","title":"生成内核镜像","keywords":"","body":"生成内核镜像 安装 binutils 工具集 为了查看和分析生成的可执行文件，我们首先需要安装一套名为 binutils 的命令行工具集，其中包含了 objdump 和 objcopy 等常用工具。 Rust 社区提供了一个 cargo-binutils 项目，可以帮助我们方便地调用 Rust 内置的 LLVM binutils。我们用以下命令安装它： 运行命令 cargo install cargo-binutils rustup component add llvm-tools-preview 之后尝试使用 rust-objdump --version 命令看看是否安装成功。 [info] rust-objdump 找不到？ cargo install 会默认将二进制文件添加到 ${HOME}/.cargo/bin 中，我们将这个路径加入到 $PATH 环境变量中之后就能找到需要的 rust-objdump 命令了。 [info] 其它选择：GNU 工具链 除了内置的 LLVM 工具链以外，我们也可以使用 GNU 工具链，其中还包含了 GCC 等 C 语言工具链。 我们可以在 https://www.sifive.com/boards#software 上去下载最新的适合自己操作系统的预编译版本。 查看生成的可执行文件 我们编译之后的产物为 os/target/riscv64imac-unknown-none-elf/debug/os，让我们先看看它的文件类型： 运行输出 $ file target/riscv64imac-unknown-none-elf/debug/os target/riscv64imac-unknown-none-elf/debug/os: ELF 64-bit LSB executable, UCB RISC-V, version 1 (SYSV), statically linked, with debug_info, not stripped 从中，我们可以看出它是一个 64 位的 elf 格式的可执行文件，架构是 RISC-V；链接方式为静态链接；not stripped 指的是里面符号表的信息未被剔除，而这些信息在调试程序时会用到，程序正常执行时通常不会使用。 接下来使用刚刚安装的工具链中的 rust-objdump 工具看看它的具体信息： 运行输出 $ rust-objdump target/riscv64imac-unknown-none-elf/debug/os -x --arch-name=riscv64 target/riscv64imac-unknown-none-elf/debug/os: file format ELF64-riscv architecture: riscv64 start address: 0x0000000000011000 Sections: Idx Name Size VMA Type 0 00000000 0000000000000000 1 .text 0000000c 0000000000011000 TEXT 2 .debug_str 000004f6 0000000000000000 3 .debug_abbrev 0000010e 0000000000000000 4 .debug_info 00000633 0000000000000000 5 .debug_aranges 00000040 0000000000000000 6 .debug_ranges 00000030 0000000000000000 7 .debug_macinfo 00000001 0000000000000000 8 .debug_pubnames 000000ce 0000000000000000 9 .debug_pubtypes 000003a2 0000000000000000 10 .debug_frame 00000068 0000000000000000 11 .debug_line 00000059 0000000000000000 12 .comment 00000012 0000000000000000 13 .symtab 00000108 0000000000000000 14 .shstrtab 000000b4 0000000000000000 15 .strtab 0000002d 0000000000000000 SYMBOL TABLE: 0000000000000000 l df *ABS* 00000000 3k1zkxjipadm3tm5 0000000000000000 .debug_frame 00000000 0000000000011000 .text 00000000 0000000000011000 .text 00000000 0000000000011000 .text 00000000 000000000001100c .text 00000000 0000000000000000 .debug_ranges 00000000 0000000000000000 .debug_info 00000000 0000000000000000 .debug_line 00000000 .Lline_table_start0 0000000000011000 g F .text 0000000c _start Program Header: PHDR off 0x0000000000000040 vaddr 0x0000000000010040 paddr 0x0000000000010040 align 2**3 filesz 0x00000000000000e0 memsz 0x00000000000000e0 flags r-- LOAD off 0x0000000000000000 vaddr 0x0000000000010000 paddr 0x0000000000010000 align 2**12 filesz 0x0000000000000120 memsz 0x0000000000000120 flags r-- LOAD off 0x0000000000001000 vaddr 0x0000000000011000 paddr 0x0000000000011000 align 2**12 filesz 0x0000000000001000 memsz 0x0000000000001000 flags r-x STACK off 0x0000000000000000 vaddr 0x0000000000000000 paddr 0x0000000000000000 align 2**64 filesz 0x0000000000000000 memsz 0x0000000000000000 flags rw- Dynamic Section: 我们按顺序逐个查看： start address：程序的入口地址 Sections：从这里我们可以看到程序各段的各种信息。后面以 debug 开头的段是调试信息 SYMBOL TABLE：符号表，从中我们可以看到程序中所有符号的地址。例如 _start 函数就位于入口地址上 Program Header：程序加载时所需的段信息 其中的 off 是它在文件中的位置，vaddr 和 paddr 是要加载到的虚拟地址和物理地址，align 规定了地址的对齐，filesz 和 memsz 分别表示它在文件和内存中的大小，flags 描述了相关权限（r 表示可读，w 表示可写，x 表示可执行） 在这里我们使用的是 -x 来查看程序的元信息，下面我们用 -d 来对代码进行反汇编： 运行输出 $ rust-objdump target/riscv64imac-unknown-none-elf/debug/os -d --arch-name=riscv64 target/riscv64imac-unknown-none-elf/debug/os: file format ELF64-riscv Disassembly of section .text: 0000000000011000 _start: 11000: 41 11 addi sp, sp, -16 11002: 06 e4 sd ra, 8(sp) 11004: 22 e0 sd s0, 0(sp) 11006: 00 08 addi s0, sp, 16 11008: 09 a0 j 2 1100a: 01 a0 j 0 可以看到其中只有一个 _start 函数，里面什么都不做，就一个死循环。 生成镜像 我们之前生成的 elf 格式可执行文件有以下特点： 含有冗余的调试信息，使得程序体积较大 需要对 Program Header 部分进行手动解析才能知道各段的信息，而这需要我们了解 Program Header 的二进制格式，并以字节为单位进行解析 由于我们目前没有调试的手段，不需要调试信息；同时也不会解析 elf 格式文件，所以我们可以使用工具 rust-objcopy 从 elf 格式可执行文件生成内核镜像： 运行命令 rust-objcopy target/riscv64imac-unknown-none-elf/debug/os --strip-all -O binary target/riscv64imac-unknown-none-elf/debug/kernel.bin 这里 --strip-all 表明丢弃所有符号表及调试信息，-O binary 表示输出为二进制文件。 至此，我们编译并生成了内核镜像 kernel.bin 文件。接下来，我们将使用 QEMU 模拟器真正将我们的内核镜像跑起来。不过在此之前还需要完成两个工作：调整内存布局和重写入口函数。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-6.html":{"url":"docs/lab-0/guide/part-6.html","title":"调整内存布局","keywords":"","body":"调整内存布局 上一节中我们看到，编译出的程序默认被放到了从 0x11000 开始的位置上： 运行输出 start address: 0x0000000000011000 ... Program Header: PHDR off 0x0000000000000040 vaddr 0x0000000000010040 ... LOAD off 0x0000000000000000 vaddr 0x0000000000010000 ... LOAD off 0x0000000000001000 vaddr 0x0000000000011000 ... STACK off 0x0000000000000000 vaddr 0x0000000000000000 ... 这是因为对于普通用户程序来说，代码和数据一般放在低地址空间上的。 对于 OS 内核，一般都将其地址空间放在高地址上。并且在QEMU模拟的 RISC-V 中，DRAM内存的物理地址是从 0x80000000 开始，有128MB大小（如想进一步了解，可参看qemu/hw/riscv/virt.c中的VIRT_DRAM的赋值，以及实验指导二中物理内存探测小节）。因此接下来我们需要调整程序的内存布局，改变它的链接地址。 [info] 程序的内存布局 一般来说，一个程序按照功能不同会分为下面这些段： .text 段：代码段，存放汇编代码 .rodata 段：只读数据段，顾名思义里面存放只读数据，通常是程序中的常量 .data 段：存放被初始化的可读写数据，通常保存程序中的全局变量 .bss 段：存放被初始化为 0 的可读写数据，与 .data 段的不同之处在于我们知道它要被初始化为 0，因此在可执行文件中只需记录这个段的大小以及所在位置即可，而不用记录里面的数据，也不会实际占用二进制文件的空间 Stack：栈，用来存储程序运行过程中的局部变量，以及负责函数调用时的各种机制。它从高地址向低地址增长 Heap：堆，用来支持程序运行过程中内存的动态分配，比如说你要读进来一个字符串，在你写程序的时候你也不知道它的长度究竟为多少，于是你只能在运行过程中，知道了字符串的长度之后，再在堆中给这个字符串分配内存 内存布局，也就是指这些段各自所放的位置。一种典型的内存布局如下： 编写链接脚本 我们使用链接脚本（Linker Script）来指定程序的内存布局。创建文件 os/src/linker.ld： os/src/linker.ld /* 有关 Linker Script 可以参考：https://sourceware.org/binutils/docs/ld/Scripts.html */ /* 目标架构 */ OUTPUT_ARCH(riscv) /* 执行入口 */ ENTRY(_start) /* 数据存放起始地址 */ BASE_ADDRESS = 0x80200000; SECTIONS { /* . 表示当前地址（location counter） */ . = BASE_ADDRESS; /* start 符号表示全部的开始位置 */ kernel_start = .; text_start = .; /* .text 字段 */ .text : { /* 把 entry 函数放在最前面 */ *(.text.entry) /* 要链接的文件的 .text 字段集中放在这里 */ *(.text .text.*) } rodata_start = .; /* .rodata 字段 */ .rodata : { /* 要链接的文件的 .rodata 字段集中放在这里 */ *(.rodata .rodata.*) } data_start = .; /* .data 字段 */ .data : { /* 要链接的文件的 .data 字段集中放在这里 */ *(.data .data.*) } bss_start = .; /* .bss 字段 */ .bss : { /* 要链接的文件的 .bss 字段集中放在这里 */ *(.sbss .bss .bss.*) } /* 结束地址 */ kernel_end = .; } 时至今日我们已经不太可能将所有代码都写在一个文件里面。在编译过程中，我们的编译器和链接器已经给每个文件都自动生成了一个内存布局。这里，我们的链接工具所要做的是最终将各个文件的内存布局装配起来生成整个内核的内存布局。 我们首先使用 OUTPUT_ARCH 指定了架构，随后使用 ENTRY 指定了入口点为 _start 函数，即程序第一条被执行的指令所在之处。在这个链接脚本中我们并未看到 _start ，回忆上一章，我们为了移除运行时环境依赖，重写了入口 _start 。所以，链接脚本宣布整个程序会从那里开始运行。 链接脚本的整体写在 SECTION{ } 中，里面有多个形如 output section: { input section list } 的语句，每个都描述了整个程序内存布局中的一个输出段 output section 是由各个文件中的哪些输入段 input section 组成的。 我们可以用 *( ) 来表示将各个文件中所有符合括号内要求的输入段放在当前的位置。而括号内，你可以直接使用段的名字，也可以包含通配符 *。 单独的一个 . 为当前地址（Location Counter），可以对其赋值来从设置的地址继续向高地址放置各个段。如果不进行赋值的话，则默认各个段会紧挨着向高地址放置。将一个符号赋值为 . 则会记录下这个符号的地址。 到这里我们大概看懂了这个链接脚本在做些什么事情。首先是从 BASE_ADDRESS 即 0x80200000 开始向下放置各个段，依次是 .text，.rodata，.data，.stack 和 .bss。同时我们还记录下了每个段的开头和结尾地址，如 .text 段的开头、结尾地址分别就是符号 stext 和 etext 的值，我们接下来会用到。 [info] 为什么是 0x80200000 OpenSBI（如想进一步了解，可参看本章的重写程序入口点小节相关的介绍）将自身放在 0x80000000，完成初始化后会跳转到 0x80200000，因此 _start 必须位于这个地址。.text 为代码段标识，其第一个放置的就是 _start（即 .text.entry）。 这里面有一个输入段与其他的不太一样，即 .text.entry，似乎编译器不会自动生成这样名字的段。事实上，它是我们在后面自己定义的。 使用链接脚本 为了在编译时使用上面自定义的链接脚本，我们在 .cargo/config 文件中加入以下配置： os/.cargo/config # 使用我们的 linker script 来进行链接 [target.riscv64imac-unknown-none-elf] rustflags = [ \"-C\", \"link-arg=-Tsrc/linker.ld\", ] 它的作用是在链接时传入一个参数 -T 来指定使用哪个链接脚本。 我们重新编译一下，然后再次查看生成的可执行文件： 运行输出 $ cargo build ... Finished dev [unoptimized + debuginfo] target(s) in 0.23s $ rust-objdump target/riscv64imac-unknown-none-elf/debug/os -h --arch-name=riscv64 target/riscv64imac-unknown-none-elf/debug/os: file format ELF64-riscv Sections: Idx Name Size VMA Type 0 00000000 0000000000000000 1 .text 0000000c 0000000080200000 TEXT 2 .rodata 00000000 000000008020000c TEXT 3 .data 00000000 000000008020000c TEXT 4 .bss 00000000 000000008020000c BSS ... $ rust-objdump target/riscv64imac-unknown-none-elf/debug/os -d --arch-name=riscv64 target/riscv64imac-unknown-none-elf/debug/os: file format ELF64-riscv Disassembly of section .text: 0000000080200000 stext: 80200000: 41 11 addi sp, sp, -16 80200002: 06 e4 sd ra, 8(sp) 80200004: 22 e0 sd s0, 0(sp) 80200006: 00 08 addi s0, sp, 16 80200008: 09 a0 j 2 8020000a: 01 a0 j 0 程序已经被正确地放在了指定的地址上。 到这里，我们清楚了最终程序的内存布局会长成什么样子。下一节我们来补充这个链接脚本中未定义的段，并完成编译。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-7.html":{"url":"docs/lab-0/guide/part-7.html","title":"重写程序入口点","keywords":"","body":"重写程序入口点 _start 我们在第一章中，曾自己重写了一个入口点 _start，在那里我们仅仅只是让它死循环。但是现在，类似 C 语言运行时环境，我们希望这个函数可以为我们设置内核的运行环境。随后，我们才真正开始执行内核的代码。 但是具体而言我们需要设置怎样的运行环境呢？ [info] 第一条指令 在 CPU 加电或 Reset 后，它首先会进行自检（POST, Power-On Self-Test），通过自检后会跳转到启动代码（Bootloader）的入口。在 bootloader 中，我们进行外设探测，并对内核的运行环境进行初步设置。随后，bootloader 会将内核代码从硬盘加载到内存中，并跳转到内核入口，正式进入内核。也就是说，CPU 所执行的第一条指令其实是指 bootloader 的第一条指令。 幸运的是， 我们已经有现成的 bootloader 实现 OpenSBI 固件（Firmware）。 [info] Firmware 固件 在计算中，固件是一种特定的计算机软件，它为设备的特定硬件提供低级控制进一步加载其他软件的功能。固件可以为设备更复杂的软件（如操作系统）提供标准化的操作环境，或者，对于不太复杂的设备，充当设备的完整操作系统，执行所有控制、监视和数据操作功能。在基于 x86 的计算机系统中, BIOS 或 UEFI 是一种固件；在基于 RISC-V 的计算机系统中，OpenSBI 是一种固件。 OpenSBI 固件运行在特权级别很高的计算机硬件环境中，即 RISC-V 64 的 M Mode（CPU 加电后也就运行在 M Mode），我们将要实现的 OS 内核运行在 S Mode，而我们要支持的用户程序运行在 U Mode。在开发过程中我们重点关注 S Mode。 [info] RISC-V 64 的特权级 RISC-V 共有 3 种特权级，分别是 U Mode（User / Application 模式）、S Mode（Supervisor 模式）和 M Mode（Machine 模式）。 从 U 到 S 再到 M，权限不断提高，这意味着你可以使用更多的特权指令，访需求权限更高的寄存器等等。我们可以使用一些指令来修改 CPU 的当前特权级。而当当前特权级不足以执行特权指令或访问一些寄存器时，CPU 会通过某种方式告诉我们。 OpenSBI 所做的一件事情就是把 CPU 从 M Mode 切换到 S Mode，接着跳转到一个固定地址 0x80200000，开始执行内核代码。 [info] RISC-V 的 M Mode Machine 模式是 RISC-V 中可以执行的最高权限模式。在机器态下运行的代码对内存、I/O 和一些对于启动和配置系统来说必要的底层功能有着完全的使用权。 RISC-V 的 S Mode Supervisor 模式是支持现代类 Unix 操作系统的权限模式，支持现代类 Unix 操作系统所需要的基于页面的虚拟内存机制是其核心。 接着我们要在 _start 中设置内核的运行环境了，我们直接来看代码： os/src/entry.asm # 操作系统启动时所需的指令以及字段 # # 我们在 linker.ld 中将程序入口设置为了 _start，因此在这里我们将填充这个标签 # 它将会执行一些必要操作，然后跳转至我们用 rust 编写的入口函数 # # 关于 RISC-V 下的汇编语言，可以参考 https://github.com/riscv/riscv-asm-manual/blob/master/riscv-asm.md .section .text.entry .globl _start # 目前 _start 的功能：将预留的栈空间写入 $sp，然后跳转至 rust_main _start: la sp, boot_stack_top call rust_main # 回忆：bss 段是 ELF 文件中只记录长度，而全部初始化为 0 的一段内存空间 # 这里声明字段 .bss.stack 作为操作系统启动时的栈 .section .bss.stack .global boot_stack boot_stack: # 16K 启动栈大小 .space 4096 * 16 .global boot_stack_top boot_stack_top: # 栈结尾 可以看到我们在 .bss 中加入了 .stack 段，并在这里分配了一块 4096×4 Bytes=16 KBytes4096\\times{4}\\text{\\ Bytes}=16 \\text{\\ KBytes}4096×4 Bytes=16 KBytes 的内存作为启动时内核的栈。之前的 .text.entry 也出现了，也就是我们将 _start 函数放在了 .text 段的开头。 我们看看 _start 里面做了什么： 修改栈指针寄存器 sp 为 .bss.stack 段的结束地址，由于栈是从高地址往低地址增长，所以高地址是初始的栈顶； 使用 call 指令跳转到 rust_main 。这意味着我们的内核运行环境设置完成了，正式进入内核。 我们将 os/src/main.rs 里面的 _start 函数删除，并换成 rust_main ： os/src/main.rs //! # 全局属性 //! - `#![no_std]` //! 禁用标准库 #![no_std] //! //! - `#![no_main]` //! 不使用 `main` 函数等全部 Rust-level 入口点来作为程序入口 #![no_main] //! //! - `#![feature(global_asm)]` //! 内嵌整个汇编文件 #![feature(global_asm)] // 汇编编写的程序入口，具体见该文件 global_asm!(include_str!(\"entry.asm\")); use core::panic::PanicInfo; /// 当 panic 发生时会调用该函数 /// 我们暂时将它的实现为一个死循环 #[panic_handler] fn panic(_info: &PanicInfo) -> ! { loop {} } /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { loop {} } 到现在为止我们终于将一切都准备好了，接下来就要配合 OpenSBI 运行我们的内核！ var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-8.html":{"url":"docs/lab-0/guide/part-8.html","title":"使用 QEMU 运行","keywords":"","body":"使用 QEMU 运行内核 使用 OpenSBI 新版 QEMU 中内置了 OpenSBI 固件，它主要负责在操作系统运行前的硬件初始化和加载操作系统的功能。我们使用以下命令尝试运行一下： 运行输出 $ qemu-system-riscv64 \\ --machine virt \\ --nographic \\ --bios default OpenSBI v0.4 (Jul 2 2019 11:53:53) ____ _____ ____ _____ / __ \\ / ____| _ \\_ _| | | | |_ __ ___ _ __ | (___ | |_) || | | | | | '_ \\ / _ \\ '_ \\ \\___ \\| _ 可以看到我们已经在 qemu-system-riscv64 模拟的 QEMU Virt Machine 硬件上将 OpenSBI 这个固件跑起来了。QEMU 可以使用 ctrl+a （macOS 为 control+a） 再按下 x 键退出。 加载内核镜像 为了确信我们已经跑起来了内核里面的代码，我们最好在 rust_main 里面加上简单的输出： os/src/main.rs //! # 全局属性 //! - `#![no_std]` //! 禁用标准库 #![no_std] //! //! - `#![no_main]` //! 不使用 `main` 函数等全部 Rust-level 入口点来作为程序入口 #![no_main] //! # 一些 unstable 的功能需要在 crate 层级声明后才可以使用 //! - `#![feature(llvm_asm)]` //! 内嵌汇编 #![feature(llvm_asm)] //! //! - `#![feature(global_asm)]` //! 内嵌整个汇编文件 #![feature(global_asm)] // 汇编编写的程序入口，具体见该文件 global_asm!(include_str!(\"entry.asm\")); use core::panic::PanicInfo; /// 当 panic 发生时会调用该函数 /// 我们暂时将它的实现为一个死循环 #[panic_handler] fn panic(_info: &PanicInfo) -> ! { loop {} } /// 在屏幕上输出一个字符，目前我们先不用了解其实现原理 pub fn console_putchar(ch: u8) { let _ret: usize; let arg0: usize = ch as usize; let arg1: usize = 0; let arg2: usize = 0; let which: usize = 1; unsafe { llvm_asm!(\"ecall\" : \"={x10}\" (_ret) : \"{x10}\" (arg0), \"{x11}\" (arg1), \"{x12}\" (arg2), \"{x17}\" (which) : \"memory\" : \"volatile\" ); } } /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { // 在屏幕上输出 \"OK\\n\" ，随后进入死循环 console_putchar(b'O'); console_putchar(b'K'); console_putchar(b'\\n'); loop {} } 这样，如果我们将内核镜像加载完成后，屏幕上出现了 OK ，就说明我们之前做的事情没有问题。 现在我们生成内核镜像要通过多条命令来完成，我们可以通过在 os 目录下建立一个 Makefile 来简化这一过程： os/Makefile TARGET := riscv64imac-unknown-none-elf MODE := debug KERNEL_FILE := target/$(TARGET)/$(MODE)/os BIN_FILE := target/$(TARGET)/$(MODE)/kernel.bin OBJDUMP := rust-objdump --arch-name=riscv64 OBJCOPY := rust-objcopy --binary-architecture=riscv64 .PHONY: doc kernel build clean qemu run # 默认 build 为输出二进制文件 build: $(BIN_FILE) # 通过 Rust 文件中的注释生成 os 的文档 doc: @cargo doc --document-private-items # 编译 kernel kernel: @cargo build # 生成 kernel 的二进制文件 $(BIN_FILE): kernel @$(OBJCOPY) $(KERNEL_FILE) --strip-all -O binary $@ # 查看反汇编结果 asm: @$(OBJDUMP) -d $(KERNEL_FILE) | less # 清理编译出的文件 clean: @cargo clean # 运行 QEMU qemu: build @qemu-system-riscv64 \\ -machine virt \\ -nographic \\ -bios default \\ -device loader,file=$(BIN_FILE),addr=0x80200000 # 一键运行 run: build qemu 这里我们通过参数 -device 来将内核镜像加载到 QEMU 中，我们指定了内核镜像文件，并告诉 OpenSBI 最后跳转到 0x80200000 这个入口地址。 最后，我们可以使用 make run 来用 Qemu 加载内核镜像并运行。匆匆翻过一串长长的 OpenSBI 输出，我们看到了 OK！于是历经了千辛万苦我们终于将我们的内核跑起来了！ 下一节我们实现格式化输出来使得我们后续能够更加方便的通过输出来进行内核调试。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/part-9.html":{"url":"docs/lab-0/guide/part-9.html","title":"接口封装和代码整理","keywords":"","body":"接口封装和代码整理 使用 OpenSBI 提供的服务 OpenSBI 实际上不仅起到了 bootloader 的作用，还为我们提供了一些底层系统服务供我们在编写内核时使用，以简化内核实现并提高内核跨硬件细节的能力。这层底层系统服务接口称为 SBI（Supervisor Binary Interface），是 S Mode 的 OS 和 M Mode 执行环境之间的标准接口约定。 参考 OpenSBI 文档 ，我们会发现里面包含了一些以 C 函数格式给出的我们可以调用的接口。 上一节中我们的 console_putchar 函数类似于调用下面的接口来实现的： void sbi_console_putchar(int ch) 而实际的过程是这样的：运行在S态的OS通过 ecall 发起SBI调用请求，RISC-V CPU会从S态跳转到M态的OpenSBI固件，OpenSBI会检查OS发起的SBI调用的编号，如果编号在 0-8 之间，则进行处理，否则交由我们自己的中断处理程序处理（暂未实现）。想进一步了解编号在 0-8 之间的系统调用，请参考看 OpenSBI 文档。 执行 ecall 前需要指定SBI调用的编号，传递参数。一般而言，a7(x17) 为SBI调用编号，a0(x10)、a1(x11) 和 a2(x12) 寄存器为SBI调用参数： os/src/sbi.rs //! 调用 Machine 层的操作 // 目前还不会用到全部的 SBI 调用，暂时允许未使用的变量或函数 #![allow(unused)] /// SBI 调用 #[inline(always)] fn sbi_call(which: usize, arg0: usize, arg1: usize, arg2: usize) -> usize { let ret; unsafe { llvm_asm!(\"ecall\" : \"={x10}\" (ret) : \"{x10}\" (arg0), \"{x11}\" (arg1), \"{x12}\" (arg2), \"{x17}\" (which) : \"memory\" // 如果汇编可能改变内存，则需要加入 memory 选项 : \"volatile\"); // \b\b\b防止编译器做激进的优化（如调换指令顺序等破坏 SBI 调用行为的优化） } ret } [info] 函数调用与 Calling Convention 我们知道，编译器将高级语言源代码翻译成汇编代码。对于汇编语言而言，在最简单的编程模型中，所能够利用的只有指令集中提供的指令、各通用寄存器、 CPU 的状态、内存资源。那么，在高级语言中，我们进行一次函数调用，编译器要做哪些工作利用汇编语言来实现这一功能呢？ 显然并不是仅用一条指令跳转到被调用函数开头地址就行了。我们还需要考虑： 如何传递参数？ 如何传递返回值？ 如何保证函数返回后能从我们期望的位置继续执行？ 等更多事项。通常编译器按照某种规范去翻译所有的函数调用，这种规范被称为 Calling Convention 。值得一提的是，为了确保被调用函数能正确执行，我们需要预先分配一块内存作为调用栈 ，后面会看到调用栈在函数调用过程中极其重要。你也可以理解为什么第一章刚开始我们就要分配栈了。 对于参数比较少且是基本数据类型的时候，我们从左到右使用寄存器 a0 到 a7 就可以完成参数的传递。具体规范可参考 RISC-V Calling Convention。 对于设置寄存器并执行汇编指令的代码编写，已经超出了 Rust 语言的基本描述能力。之前采用的global_asm! 方式在Rust代码中插入汇编代码，还不太方便实现Rust代码与汇编代码的互操作。为有效编写 Rust代码与汇编代码的互操作，我们还有另外一种内联汇编（Inline Assembly）方式， 可相对简单地完成诸如把 u8 类型的单个字符传给 a0 作为输入参数的编码需求。内联汇编（Inline Assembly）的具体规范请参考书籍：Rust编程。 输出部分，我们将结果保存到变量 ret 中，限制条件 {x10} 告诉编译器使用寄存器 x10（即 a0 寄存器），前面的 = 表明汇编代码会修改该寄存器并作为最后的返回值。 输入部分，我们分别通过寄存器 x10、x11、x12 和 x17（这四个寄存器又名 a0、a1、a2 和 a7） 传入参数 arg0、arg1、arg2 和 which ，其中前三个参数分别代表接口可能所需的三个输入参数，最后一个 which 用来区分我们调用的是哪个接口（SBI Extension ID）。这里之所以提供三个输入参数是为了将所有接口囊括进去，对于某些接口有的输入参数是冗余的，比如 sbi_console_putchar 由于只需一个输入参数，它就只关心寄存器 a0 的值。 接着利用 sbi_call 函数参考 OpenSBI 文档实现对应的接口，顺带也可以把关机函数通过 SBI 接口一并实现： os/src/sbi.rs const SBI_SET_TIMER: usize = 0; const SBI_CONSOLE_PUTCHAR: usize = 1; const SBI_CONSOLE_GETCHAR: usize = 2; const SBI_CLEAR_IPI: usize = 3; const SBI_SEND_IPI: usize = 4; const SBI_REMOTE_FENCE_I: usize = 5; const SBI_REMOTE_SFENCE_VMA: usize = 6; const SBI_REMOTE_SFENCE_VMA_ASID: usize = 7; const SBI_SHUTDOWN: usize = 8; /// 向控制台输出一个字符 /// /// 需要注意我们不能直接使用 Rust 中的 char 类型 pub fn console_putchar(c: usize) { sbi_call(SBI_CONSOLE_PUTCHAR, c, 0, 0); } /// 从控制台中读取一个字符 /// /// 没有读取到字符则返回 -1 pub fn console_getchar() -> usize { sbi_call(SBI_CONSOLE_GETCHAR, 0, 0, 0) } /// 调用 SBI_SHUTDOWN 来关闭操作系统（直接退出 QEMU） pub fn shutdown() -> ! { sbi_call(SBI_SHUTDOWN, 0, 0, 0); unreachable!() } 现在我们比较深入的理解了 console_putchar 到底是怎么一回事。下面我们使用 console_putchar 实现格式化输出，为后面的调试提供方便。 实现格式化输出 只能使用 console_putchar 这种苍白无力的输出手段让人头皮发麻。如果我们能使用 println! 宏的话该有多好啊！于是我们就来实现自己的 print!宏和 println!宏！ 我们将这一部分放在 os/src/conosle.rs 中，关于格式化输出，Rust 中提供了一个接口 core::fmt::Write，你需要实现函数： fn write_str(&mut self, s: &str) -> Result 随后我们就可以调用如下函数（会进一步调用write_str 实现函数）来进行显示： fn write_fmt(mut self: &mut Self, args: Arguments) -> Result write_fmt 函数需要处理 Arguments 类封装的输出字符串。而我们已经有现成的 format_args! 宏，它可以将模式字符串和参数列表的输入转化为 Arguments 类，比如 format_args!(\"{} {}\", 1, 2) 。 因此，我们宏的实现思路便为： 解析传入参数，转化为 format_args! 可接受的输入（事实上原封不动就行了），并通过 format_args! 宏得到 Arguments 类 调用 write_fmt 函数输出这个类 而为了调用 write_fmt 函数，我们必须实现 write_str 函数，而它可用 console_putchar 函数来实现。 最后，我们把整个 print 和 println 宏按照逻辑写出即可，整体逻辑的代码如下： os/src/console.rs //! 实现控制台的字符输入和输出 //! //! # 格式化输出 //! //! [`core::fmt::Write`] trait 包含 //! - 需要实现的 [`write_str`] 方法 //! - 自带实现，但依赖于 [`write_str`] 的 [`write_fmt`] 方法 //! //! 我们声明一个类型，为其实现 [`write_str`] 方法后，就可以使用 [`write_fmt`] 来进行格式化输出 //! //! [`write_str`]: core::fmt::Write::write_str //! [`write_fmt`]: core::fmt::Write::write_fmt use crate::sbi::*; use core::fmt::{self, Write}; /// 一个 [Zero-Sized Type]，实现 [`core::fmt::Write`] trait 来进行格式化输出 /// /// ZST 只可能有一个值（即为空），因此它本身就是一个单件 struct Stdout; impl Write for Stdout { /// 打印一个字符串 /// /// [`console_putchar`] sbi 调用每次接受一个 `usize`，但实际上会把它作为 `u8` 来打印字符。 /// 因此，如果字符串中存在非 ASCII 字符，需要在 utf-8 编码下，对于每一个 `u8` 调用一次 [`console_putchar`] fn write_str(&mut self, s: &str) -> fmt::Result { let mut buffer = [0u8; 4]; for c in s.chars() { for code_point in c.encode_utf8(&mut buffer).as_bytes().iter() { console_putchar(*code_point as usize); } } Ok(()) } } /// 打印由 [`core::format_args!`] 格式化后的数据 /// /// [`print!`] 和 [`println!`] 宏都将展开成此函数 /// /// [`core::format_args!`]: https://doc.rust-lang.org/nightly/core/macro.format_args.html pub fn print(args: fmt::Arguments) { Stdout.write_fmt(args).unwrap(); } /// 实现类似于标准库中的 `print!` 宏 /// /// 使用实现了 [`core::fmt::Write`] trait 的 [`console::Stdout`] #[macro_export] macro_rules! print { ($fmt: literal $(, $($arg: tt)+)?) => { $crate::console::print(format_args!($fmt $(, $($arg)+)?)); } } /// 实现类似于标准库中的 `println!` 宏 /// /// 使用实现了 [`core::fmt::Write`] trait 的 [`console::Stdout`] #[macro_export] macro_rules! println { ($fmt: literal $(, $($arg: tt)+)?) => { $crate::console::print(format_args!(concat!($fmt, \"\\n\") $(, $($arg)+)?)); } } 整理 panic 处理模块 最后，我们用刚刚实现的格式化输出和关机的函数，将 main.rs 中处理 panic 的语义项抽取并完善到 panic.rs 中： os/src/panic.rs //! 代替 std 库，实现 panic 和 abort 的功能 use core::panic::PanicInfo; use crate::sbi::shutdown; /// 打印 panic 的信息并 [`shutdown`] /// /// ### `#[panic_handler]` 属性 /// 声明此函数是 panic 的回调 #[panic_handler] fn panic_handler(info: &PanicInfo) -> ! { // `\\x1b[??m` 是控制终端字符输出格式的指令，在支持的平台上可以改变文字颜色等等，这里使用红色 // 参考：https://misc.flogisoft.com/bash/tip_colors_and_formatting // // 需要全局开启 feature(panic_info_message) 才可以调用 .message() 函数 println!(\"\\x1b[1;31mpanic: '{}'\\x1b[0m\", info.message().unwrap()); shutdown() } /// 终止程序 /// /// 调用 [`panic_handler`] #[no_mangle] extern \"C\" fn abort() -> ! { panic!(\"abort()\") } 检验我们的成果 最后，我们可以 os/src/main.rs 中去掉之前写的 console_putchar并调用我们新写的一系列函数，并在 Rust 入口处加入一些简单的输出看一看我们的逻辑是否正确： os/src/main.rs //! # 全局属性 //! - `#![no_std]` //! 禁用标准库 #![no_std] //! //! - `#![no_main]` //! 不使用 `main` 函数等全部 Rust-level 入口点来作为程序入口 #![no_main] //! # 一些 unstable 的功能需要在 crate 层级声明后才可以使用 //! - `#![feature(llvm_asm)]` //! 内嵌汇编 #![feature(llvm_asm)] //! //! - `#![feature(global_asm)]` //! 内嵌整个汇编文件 #![feature(global_asm)] //! //! - `#![feature(panic_info_message)]` //! panic! 时，获取其中的信息并打印 #![feature(panic_info_message)] #[macro_use] mod console; mod panic; mod sbi; // 汇编编写的程序入口，具体见该文件 global_asm!(include_str!(\"entry.asm\")); /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { println!(\"Hello rCore-Tutorial!\"); panic!(\"end of rust_main\") } 在命令行中输入 make run，我们成功看到了 println 宏输出的 Hello rCore-Tutorial! 和一行红色的 panic: 'end of rust_main'！ var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-0/guide/summary.html":{"url":"docs/lab-0/guide/summary.html","title":"小结","keywords":"","body":"小结 本章作为一个预备实验，用 Rust 实现了一个最小化的内核，并成功通过 QEMU 中的 OpenSBI 启动了我们的内核。在下一章中，我们会和硬件进一步打交道，实现中断机制。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/guide/intro.html":{"url":"docs/lab-1/guide/intro.html","title":"摘要","keywords":"","body":"实验指导一 实验概要 这一章的实验指导中，我们将会学习 RISC-V 中有关中断处理的寄存器和相关流程 如何保存上下文，使得中断处理流程前后，原本正在执行的程序感知不到发生了中断 处理最简单的断点中断和时钟中断 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/guide/part-1.html":{"url":"docs/lab-1/guide/part-1.html","title":"什么是中断","keywords":"","body":"什么是中断 中断是我们在操作系统上首先实现的功能，因为它是操作系统所有功能的基础。假如没有中断，操作系统在唤起一个用户程序之后，就只能等到用户程序执行完成之后才能继续执行，那操作系统完全无法进行资源调度。 一个比喻 操作系统就像家长，他将孩子（用户程序）送到学校（开始运行）之后便不再管。 但是如果孩子闯了祸，老师（硬件）就找到家长，这便是异常 孩子的作业可能需要家长来签字（系统调用），他就会主动找家长，这便是陷阱 放学时间（时钟中断）到，那么不管孩子想不想回家，家长都会把他接走，这便是硬件中断 中断的种类 异常（Exception） 执行指令时产生的，通常无法预料的错误。例如：访问无效内存地址、执行非法指令（除以零）等。 有的异常可以恢复，例如缺页异常；有的异常会导致用户程序被终止，例如非法访问。 陷阱（Trap） 陷阱是一系列强行导致中断的指令，例如：系统调用（Syscall）等。 硬件中断（Hardware Interrupt） 前两种都是指令导致的异常，而硬件中断是由 CPU 之外的硬件产生的异步中断，例如：时钟中断、外设发来数据等。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/guide/part-2.html":{"url":"docs/lab-1/guide/part-2.html","title":"RISC-V 中的中断","keywords":"","body":"RISC-V 与中断相关的寄存器和指令 [info] 回顾：RISC-V 中的机器态（Machine Mode，机器模式，M 模式） 是 RISC-V 中的最高权限模式，一些底层操作的指令只能由机器态进行使用。 是所有标准 RISC-V 处理器都必须实现的模式。 默认所有中断实际上是交给机器态处理的，但是为了实现更多功能，机器态会将某些中断交由内核态处理。这些异常也正是我们编写操作系统所需要实现的。 回顾：RISC-V 中的内核态（Supervisor Mode，内核模式，S 模式） 通常为操作系统使用，可以访问一些 supervisor 级别的寄存器，通过这些寄存器对中断和虚拟内存映射进行管理。 Unix 系统中，大部分的中断都是内核态的系统调用。机器态可以通过异常委托机制（Machine Interrupt Delegation）将一部分中断设置为不经过机器态，直接由内核态处理 在实验中，我们主要关心的就是内核态可以使用的一些特权指令和寄存器。其中关于中断的会在本章用到，而关于内存映射的部分将会在第三部分用到。 与中断相关的寄存器 在内核态和机器态中，RISC-V 设计了一些 CSR（Control and Status Registers）寄存器用来保存控制信息。目前我们关心的是其中涉及到控制中断的寄存器。 发生中断时，硬件自动填写的寄存器 sepc即 Exception Program Counter，用来记录触发中断的指令的地址。 和我们之前学的 MIPS 32 系统不同，RISC-V 中不需要考虑延迟槽的问题。但是 RISC-V 中的指令不定长，如果中断处理需要恢复到异常指令后一条指令进行执行，就需要正确判断将 pc 寄存器加上多少字节。 scause记录中断是否是硬件中断，以及具体的中断原因。 stvalscause 不足以存下中断所有的必须信息。例如缺页异常，就会将 stval 设置成需要访问但是不在内存中的地址，以便于操作系统将这个地址所在的页面加载进来。 指导硬件处理中断的寄存器 stvec设置内核态中断处理流程的入口地址。存储了一个基址 BASE 和模式 MODE： MODE 为 0 表示 Direct 模式，即遇到中断便跳转至 BASE 进行执行。 MODE 为 1 表示 Vectored 模式，此时 BASE 应当指向一个向量，存有不同处理流程的地址，遇到中断会跳转至 BASE + 4 * cause 进行处理流程。 sstatus具有许多状态位，控制全局中断使能等。 sie即 Supervisor Interrupt Enable，用来控制具体类型中断的使能，例如其中的 STIE 控制时钟中断使能。 sip即 Supervisor Interrupt Pending，和 sie 相对应，记录每种中断是否被触发。仅当 sie 和 sip 的对应位都为 1 时，意味着开中断且已发生中断，这时中断最终触发。 sscratch （这个寄存器的用处会在实现线程时起到作用，目前仅了解即可） 在用户态，sscratch 保存内核栈的地址；在内核态，sscratch 的值为 0。 为了能够执行内核态的中断处理流程，仅有一个入口地址是不够的。中断处理流程很可能需要使用栈，而程序当前的用户栈是不安全的。因此，我们还需要一个预设的安全的栈空间，存放在这里。 在内核态中，sp 可以认为是一个安全的栈空间，sscratch 便不需要保存任何值。此时将其设为 0，可以在遇到中断时通过 sscratch 中的值判断中断前程序是否处于内核态。 与中断相关的指令 进入和退出中断 ecall触发中断，进入更高一层的中断处理流程之中。用户态进行系统调用进入内核态中断处理流程，内核态进行 SBI 调用进入机器态中断处理流程，使用的都是这条指令。 sret从内核态返回用户态，同时将 pc 的值设置为 sepc。（如果需要返回到 sepc 后一条指令，就需要在 sret 之前修改 sepc 的值） ebreak触发一个断点。 mret从机器态返回内核态，同时将 pc 的值设置为 mepc。 操作 CSR 只有一系列特殊的指令（CSR Instruction）可以读写 CSR。尽管所有模式都可以使用这些指令，用户态只能只读的访问某几个寄存器。 为了让操作 CSR 的指令不被干扰，许多 CSR 指令都是结合了读写的原子操作。不过在实验中，我们只用到几个简单的指令。 csrrw dst, csr, src（CSR Read Write）同时读写的原子操作，将指定 CSR 的值写入 dst，同时将 src 的值写入 CSR。 csrr dst, csr（CSR Read）仅读取一个 CSR 寄存器。 csrw csr, src（CSR Write）仅写入一个 CSR 寄存器。 csrc(i) csr, rs1（CSR Clear）将 CSR 寄存器中指定的位清零，csrc 使用通用寄存器作为 mask，csrci 则使用立即数。 csrs(i) csr, rs1（CSR Set）将 CSR 寄存器中指定的位置 1，csrc 使用通用寄存器作为 mask，csrci 则使用立即数。 了解更多 RISC-V 官方文档： CSR 寄存器（Chapter 4，p59）https://content.riscv.org/wp-content/uploads/2017/05/riscv-privileged-v1.10.pdf CSR 指令（Section 2.8，p33）https://content.riscv.org/wp-content/uploads/2017/05/riscv-spec-v2.2.pdf var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/guide/part-3.html":{"url":"docs/lab-1/guide/part-3.html","title":"程序运行状态","keywords":"","body":"程序运行状态 对于用户程序而言，中断的处理应当是不留任何痕迹的：只要中断处理改动了一个寄存器，都可能导致原本正在运行的线程出现错误。因此，在处理中断之前，必须要保存所有可能被修改的寄存器，并且在处理完成后恢复。因此，我们需要保存所有通用寄存器，sepc、scause 和 stval 这三个会被硬件自动写入的 CSR 寄存器，以及 sstatus。因为中断可能会涉及到权限的切换，以及中断的开关，这些都会修改 sstatus。 Context 我们把在中断时保存了各种寄存器的结构体叫做 Context，他表示原来程序正在执行所在的上下文（这个概念在后面线程的部分还会用到），这里我们和 scause 以及 stval 作为一个区分，后两者将不会放在 Context 而仅仅被看做一个临时的变量（在后面会被用到），Context 的定义如下： os/src/interrupt/context.rs use riscv::register::{sstatus::Sstatus, scause::Scause}; #[repr(C)] pub struct Context { pub x: [usize; 32], // 32 个通用寄存器 pub sstatus: Sstatus, pub sepc: usize } 这里我们使用了 rCore 中的库 riscv 封装的一些寄存器操作，需要在 os/Cargo.toml 中添加依赖。 os/Cargo.toml [dependencies] riscv = { git = \"https://github.com/rcore-os/riscv\", features = [\"inline-asm\"] } var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/guide/part-4.html":{"url":"docs/lab-1/guide/part-4.html","title":"状态的保存与恢复","keywords":"","body":"状态的保存与恢复 操作流程 为了状态的保存与恢复，我们可以先用栈上的一小段空间来把需要保存的全部通用寄存器和 CSR 寄存器保存在栈上，保存完之后在跳转到 Rust 编写的中断处理函数；而对于恢复，则直接把备份在栈上的内容写回寄存器。由于涉及到了寄存器级别的操作，我们需要用汇编来实现。 而对于如何保存在栈上，我们可以直接令 sp 栈寄存器直接减去相应需要开辟的大小，然后依次放在栈上。需要注意的是，sp 寄存器又名 x2，我们需要不断用到这个寄存器告诉 CPU 其他寄存器放在哪个地址，所以处理这个 sp 寄存器本身的保存时也需要格外小心。 编写汇编 因为汇编代码较长，这里我们新建一个 os/src/interrupt.asm 文件来编写这段操作： os/src/interrupt.asm # 宏：将寄存器存到栈上 .macro SAVE reg, offset sd \\reg, \\offset*8(sp) .endm # 宏：将寄存器从栈中取出 .macro LOAD reg, offset ld \\reg, \\offset*8(sp) .endm .section .text .globl __interrupt # 进入中断 # 保存 Context 并且进入 Rust 中的中断处理函数 interrupt::handler::handle_interrupt() __interrupt: # 在栈上开辟 Context 所需的空间 addi sp, sp, -34*8 # 保存通用寄存器，除了 x0（固定为 0） SAVE x1, 1 # 将原来的 sp（sp 又名 x2）写入 2 位置 addi x1, sp, 34*8 SAVE x1, 2 # 其他通用寄存器 SAVE x3, 3 SAVE x4, 4 SAVE x5, 5 SAVE x6, 6 SAVE x7, 7 SAVE x8, 8 SAVE x9, 9 SAVE x10, 10 SAVE x11, 11 SAVE x12, 12 SAVE x13, 13 SAVE x14, 14 SAVE x15, 15 SAVE x16, 16 SAVE x17, 17 SAVE x18, 18 SAVE x19, 19 SAVE x20, 20 SAVE x21, 21 SAVE x22, 22 SAVE x23, 23 SAVE x24, 24 SAVE x25, 25 SAVE x26, 26 SAVE x27, 27 SAVE x28, 28 SAVE x29, 29 SAVE x30, 30 SAVE x31, 31 # 取出 CSR 并保存 csrr s1, sstatus csrr s2, sepc SAVE s1, 32 SAVE s2, 33 # 调用 handle_interrupt，传入参数 # context: &mut Context mv a0, sp # scause: Scause csrr a1, scause # stval: usize csrr a2, stval jal handle_interrupt .globl __restore # 离开中断 # 从 Context 中恢复所有寄存器，并跳转至 Context 中 sepc 的位置 __restore: # 恢复 CSR LOAD s1, 32 LOAD s2, 33 csrw sstatus, s1 csrw sepc, s2 # 恢复通用寄存器 LOAD x1, 1 LOAD x3, 3 LOAD x4, 4 LOAD x5, 5 LOAD x6, 6 LOAD x7, 7 LOAD x8, 8 LOAD x9, 9 LOAD x10, 10 LOAD x11, 11 LOAD x12, 12 LOAD x13, 13 LOAD x14, 14 LOAD x15, 15 LOAD x16, 16 LOAD x17, 17 LOAD x18, 18 LOAD x19, 19 LOAD x20, 20 LOAD x21, 21 LOAD x22, 22 LOAD x23, 23 LOAD x24, 24 LOAD x25, 25 LOAD x26, 26 LOAD x27, 27 LOAD x28, 28 LOAD x29, 29 LOAD x30, 30 LOAD x31, 31 # 恢复 sp（又名 x2）这里最后恢复是为了上面可以正常使用 LOAD 宏 LOAD x2, 2 sret 这样的话我们就完成了对当前执行现场保存，我们把 Context 以及 scause 和 stval 作为参数传入了 handle_interrupt 函数中，这是一个 Rust 编写的函数，后面我们将会实现它。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/guide/part-5.html":{"url":"docs/lab-1/guide/part-5.html","title":"进入中断处理流程","keywords":"","body":"进入中断处理流程 接下来，我们将要手动触发一个 Trap（ebreak），并且进入中断处理流程。 开启中断 为了让硬件能够找到我们编写的 __interrupt 入口，在操作系统初始化时，需要将其写入 stvec 寄存器中： os/src/interrupt/handler.rs use super::context::Context; use riscv::register::stvec; global_asm!(include_str!(\"./interrupt.asm\")); /// 初始化中断处理 /// /// 把中断入口 `__interrupt` 写入 `stvec` 中，并且开启中断使能 pub fn init() { unsafe { extern \"C\" { /// `interrupt.asm` 中的中断入口 fn __interrupt(); } // 使用 Direct 模式，将中断入口设置为 `__interrupt` stvec::write(__interrupt as usize, stvec::TrapMode::Direct); } } 处理中断 然后，我们再补上 __interrupt 后跳转的中断处理流程 handle_interrupt()： os/src/interrupt/handler.rs /// 中断的处理入口 /// /// `interrupt.asm` 首先保存寄存器至 Context，其作为参数和 scause 以及 stval 一并传入此函数 /// 具体的中断类型需要根据 scause 来推断，然后分别处理 #[no_mangle] pub fn handle_interrupt(context: &mut Context, scause: Scause, stval: usize) { panic!(\"Interrupted: {:?}\", scause.cause()); } 触发中断 最后，我们把刚刚写的函数封装一下： os/src/interrupt/mod.rs //! 中断模块 //! //! mod handler; mod context; /// 初始化中断相关的子模块 /// /// - [`handler::init`] /// - [`timer::init`] pub fn init() { handler::init(); println!(\"mod interrupt initialized\"); } 同时，我们在 main 函数中主动使用 ebreak 来触发一个中断。 os/src/main.rs ... mod interrupt; ... /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 pub extern \"C\" fn rust_main() -> ! { // 初始化各种模块 interrupt::init(); unsafe { llvm_asm!(\"ebreak\"::::\"volatile\"); }; unreachable!(); } 运行一下，可以看到 ebreak 导致程序进入了中断处理并退出，而没有执行到后面的 unreachable!()： 运行输出 Hello rCore-Tutorial! mod interrupt initialized panic: 'Interrupted: Exception(Breakpoint)' var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/guide/part-6.html":{"url":"docs/lab-1/guide/part-6.html","title":"时钟中断","keywords":"","body":"时钟中断 本章的最后，我们来实现操作系统中极其重要的时钟中断。时钟中断是操作系统能够进行线程调度的基础，操作系统会在每次时钟中断时被唤醒，暂停正在执行的线程，并根据调度算法选择下一个应当运行的线程。 [info] RISC-V 中断寄存器的细分 在前面提到，sie 和 sip 寄存器分别保存不同中断种类的使能和触发记录。例如，软件中断的使能是 sie 中的 SSIE 位，触发记录是 sip 中的 SSIP 位。 RISC-V 中将中断分为三种： 软件中断（Software Interrupt），对应 SSIE 和 SSIP 时钟中断（Timer Interrupt），对应 STIE 和 STIP 外部中断（External Interrupt），对应 SEIE 和 SEIP 开启时钟中断 时钟中断也需要我们在初始化操作系统时开启，我们同样只需使用 riscv 库中提供的接口即可。 os/src/interrupt/timer.rs //! 预约和处理时钟中断 use crate::sbi::set_timer; use riscv::register::{time, sie, sstatus}; /// 初始化时钟中断 /// /// 开启时钟中断使能，并且预约第一次时钟中断 pub fn init() { unsafe { // 开启 STIE，允许时钟中断 sie::set_stimer(); // 开启 SIE（不是 sie 寄存器），允许内核态被中断打断 sstatus::set_sie(); } // 设置下一次时钟中断 set_next_timeout(); } 这里可能引起误解的是 sstatus::set_sie()，它的作用是开启 sstatus 寄存器中的 SIE 位，与 sie 寄存器无关。SIE 位决定中断是否能够打断 supervisor 线程。在这里我们需要允许时钟中断打断 内核态线程，因此置 SIE 位为 1。另外，无论 SIE 位为什么值，中断都可以打断用户态的线程。 设置时钟中断 每一次的时钟中断都需要操作系统设置一个下一次中断的时间，这样硬件会在指定的时间发出时钟中断。为简化操作系统实现，操作系统可请求(sbi_call调用ecall指令)SBI服务来完成时钟中断的设置。OpenSBI固件在接到SBI服务请求后，会帮助OS设置下一次要触发时钟中断的时间，CPU 在执行过程中会检查当前的时间间隔是否已经超过设置的时钟中断时间间隔，如果超时则会触发时钟中断。 os/src/sbi.rs /// 设置下一次时钟中断的时间 pub fn set_timer(time: usize) { sbi_call(SBI_SET_TIMER, time, 0, 0); } 为了便于后续处理，我们设置时钟间隔为 100000 个 CPU 周期。越短的间隔可以让 CPU 调度资源更加细致，但同时也会导致更多资源浪费在操作系统上。 os/src/interrupt/timer.rs /// 时钟中断的间隔，单位是 CPU 指令 static INTERVAL: usize = 100000; /// 设置下一次时钟中断 /// /// 获取当前时间，加上中断间隔，通过 SBI 调用预约下一次中断 fn set_next_timeout() { set_timer(time::read() + INTERVAL); } 由于没有一个接口来设置固定重复的时间中断间隔，因此我们需要在每一次时钟中断时，设置再下一次的时钟中断。 os/src/interrupt/timer.rs /// 触发时钟中断计数 pub static mut TICKS: usize = 0; /// 每一次时钟中断时调用 /// /// 设置下一次时钟中断，同时计数 +1 pub fn tick() { set_next_timeout(); unsafe { TICKS += 1; if TICKS % 100 == 0 { println!(\"{} tick\", TICKS); } } } 实现时钟中断的处理流程 接下来，我们在 handle_interrupt() 根据不同中断种类进行不同的处理流程。 os/src/interrupt/handler.rs /// 中断的处理入口 /// /// `interrupt.asm` 首先保存寄存器至 Context，其作为参数和 scause 以及 stval 一并传入此函数 /// 具体的中断类型需要根据 scause 来推断，然后分别处理 #[no_mangle] pub fn handle_interrupt(context: &mut Context, scause: Scause, stval: usize) { // 可以通过 Debug 来查看发生了什么中断 // println!(\"{:x?}\", context.scause.cause()); match scause.cause() { // 断点中断（ebreak） Trap::Exception(Exception::Breakpoint) => breakpoint(context), // 时钟中断 Trap::Interrupt(Interrupt::SupervisorTimer) => supervisor_timer(context), // 其他情况，终止当前线程 _ => fault(context, scause, stval), } } /// 处理 ebreak 断点 /// /// 继续执行，其中 `sepc` 增加 2 字节，以跳过当前这条 `ebreak` 指令 fn breakpoint(context: &mut Context) { println!(\"Breakpoint at 0x{:x}\", context.sepc); context.sepc += 2; } /// 处理时钟中断 /// /// 目前只会在 [`timer`] 模块中进行计数 fn supervisor_timer(_: &Context) { timer::tick(); } /// 出现未能解决的异常 fn fault(context: &mut Context, scause: Scause, stval: usize) { panic!( \"Unresolved interrupt: {:?}\\n{:x?}\\nstval: {:x}\", scause.cause(), context, stval ); } 至此，时钟中断就可以正常工作了。我们在 os/interrupt/mod.rs 中引入 mod timer 并在 初始化 handler::init() 语句的后面加入 timer::init() 就成功加载了模块。 最后我们在 main 函数中去掉 unreachable!()，然后观察时钟中断。应当可以看到程序每隔一秒左右进行一次输出 100 ticks 200 ticks…… var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/guide/summary.html":{"url":"docs/lab-1/guide/summary.html","title":"小结","keywords":"","body":"小结 本章完成了 RISC-V 中有关中断处理的部分，我们实现了中断相关的上下文保存和切换，使得原来正在的运行的程序不需要做任何处理就可以让操作系统处理好中断/异常。我们进一步完成了简单的断点中断和时钟中断，展示了中断处理的执行过程，为后面的章节（包括系统调用的处理）打下了一定的基础。 在下一章节中，我们将从物理内存的管理出发，让操作系统真正可以去管理我们的可以使用的内存。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-2/guide/intro.html":{"url":"docs/lab-2/guide/intro.html","title":"摘要","keywords":"","body":"实验指导二 实验概要 这一章的实验指导中，你将会学到： 实现动态内存的分配 了解 QEMU 模拟的RISC-V Virt 计算机的物理内存 通过页的方式对物理内存进行管理 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-2/guide/part-1.html":{"url":"docs/lab-2/guide/part-1.html","title":"动态内存分配","keywords":"","body":"动态内存分配 我们之前在 C/C++ 语言等中使用过 malloc/free 等动态内存分配方法，与在编译期就已完成的静态内存分配相比，动态内存分配可以根据程序运行时状态修改内存申请的时机及大小，显得更为灵活，但是这是需要操作系统的支持的，同时也会带来一些开销。 我们的内核中也需要动态内存分配。典型的应用场景有： Box ，你可以理解为它和 malloc 有着相同的功能； 引用计数 Rc，原子引用计数 Arc，主要用于在引用计数清零，即某对象不再被引用时，对该对象进行自动回收； 一些 Rust std 标准库中的数据结构，如 Vec 和 HashMap 等。 我们编写的操作系统不能直接使用Rust std 标准库提供的动态内存分配功能，因为这些功能需要底层操作系统的支持，这就形成了递归依赖的矛盾了。为了在我们的内核中支持动态内存分配，在 Rust 语言中，我们需要实现 Trait GlobalAlloc，将这个类实例化，并使用语义项 #[global_allocator] 进行标记。这样的话，编译器就会知道如何使用我们提供的内存分配函数进行动态内存分配。 为了实现 Trait GlobalAlloc，我们需要支持这么两个函数： unsafe fn alloc(&self, layout: Layout) -> *mut u8; unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout); 可见我们要分配/回收一块虚拟内存。 那么这里面的 Layout 又是什么呢？从文档中可以找到，它有两个字段：size 表示要分配的字节数，align 则表示分配的虚拟地址的最小对齐要求，即分配的地址要求是 align 的倍数。这里的 align 必须是 2 的幂次。 也就表示，我们的需求是分配一块连续的、大小至少为 size 字节的虚拟内存，且对齐要求为 align 。 连续内存分配算法 假设我们已经有一整块虚拟内存用来分配，那么如何进行分配呢？ 我们可能会想到一些简单粗暴的方法，比如对于一个分配任务，贪心地将其分配到可行的最小地址去。这样一直分配下去的话，我们分配出去的内存都是连续的，看上去很合理的利用了内存。 但是一旦涉及到回收的话，设想我们在连续分配出去的很多块内存中间突然回收掉一块，它虽然是可用的，但是由于上下两边都已经被分配出去，它就只有这么大而不能再被拓展了，这种可用的内存我们称之为外碎片。 随着不断回收会产生越来越多的碎片，某个时刻我们可能会发现，需要分配一块较大的内存，几个碎片加起来大小是足够的，但是单个碎片是不够的。我们会想到通过碎片整理将几个碎片合并起来。但是这个过程的开销极大。 在操作系统课程上，我们了解到还有若干更有效的内存分配算法，包括伙伴系统（Buddy System）和 SLAB 分配器等算法，我们在这里使用 Buddy System 来实现这件事情。 支持动态内存分配 为了避免重复造轮子，我们可以直接开一个静态的 8M 数组作为堆的空间，然后调用 @jiege 开发的 Buddy System Allocator。 os/src/memory/config.rs /// 操作系统动态分配内存所用的堆大小（8M） pub const KERNEL_HEAP_SIZE: usize = 0x80_0000; os/src/memory/heap.rs /// 进行动态内存分配所用的堆空间 /// /// 大小为 [`KERNEL_HEAP_SIZE`] /// 这段空间编译后会被放在操作系统执行程序的 bss 段 static mut HEAP_SPACE: [u8; KERNEL_HEAP_SIZE] = [0; KERNEL_HEAP_SIZE]; /// 堆，动态内存分配器 /// /// ### `#[global_allocator]` /// [`LockedHeap`] 实现了 [`alloc::alloc::GlobalAlloc`] trait， /// 可以为全局需要用到堆的地方分配空间。例如 `Box` `Arc` 等 #[global_allocator] static HEAP: LockedHeap = LockedHeap::empty(); /// 初始化操作系统运行时堆空间 pub fn init() { // 告诉分配器使用这一段预留的空间作为堆 unsafe { HEAP.lock().init( HEAP_SPACE.as_ptr() as usize, KERNEL_HEAP_SIZE ) } } /// 空间分配错误的回调，直接 panic 退出 #[alloc_error_handler] fn alloc_error_handler(_: alloc::alloc::Layout) -> ! { panic!(\"alloc error\") } 同时还有一些模块调用等细节代码，这里不再贴出，请参考完成本章后的仓库中的代码。 动态内存分配测试 现在我们来测试一下动态内存分配是否有效，分配一个动态数组： os/src/main.rs /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { // 初始化各种模块 interrupt::init(); memory::init(); // 动态内存分配测试 use alloc::boxed::Box; use alloc::vec::Vec; let v = Box::new(5); assert_eq!(*v, 5); core::mem::drop(v); let mut vec = Vec::new(); for i in 0..10000 { vec.push(i); } assert_eq!(vec.len(), 10000); for (i, value) in vec.into_iter().enumerate() { assert_eq!(value, i); } println!(\"heap test passed\"); panic!() } 最后，运行一下会看到 heap test passed 类似的输出。有了这个工具之后，后面我们就可以使用一系列诸如 Vec 等基于动态分配实现的库中的结构了。 思考 动态分配的内存地址在哪个范围里？ Click to show 在 .bss 段中，因为我们用来存放动态分配的这段是一个静态的没有初始化的数组，算是内核代码的一部分。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-2/guide/part-2.html":{"url":"docs/lab-2/guide/part-2.html","title":"物理内存探测","keywords":"","body":"物理内存探测 物理内存的相关概念 我们知道，物理地址访问的通常是一片 DRAM，我们可以把它看成一个以字节为单位的大数组，通过物理地址找到对应的位置进行读写。但是，物理地址并不仅仅只能访问 DRAM，也可以用来访问其他的外设，因此你也可以认为 DRAM 也算是一种外设，物理地址则是一个对可以存储的介质的一种抽象。 而如果访问其他外设要使用不同的指令（如 x86 单独提供了 in 和 out 等指令来访问不同于内存的 IO 地址空间），会比较麻烦；于是，很多指令集架构（如 RISC-V、ARM 和 MIPS 等）通过 MMIO（Memory Mapped I/O）技术将外设映射到一段物理地址，这样我们访问其他外设就和访问物理内存一样了。 我们先不管那些外设，来看物理内存。 物理内存探测 操作系统怎样知道物理内存所在的那段物理地址呢？在 RISC-V 中，这个一般是由Bootloader ，即OpenSBI固件来完成的。它来完成对于包括物理内存在内的各外设的扫描，将扫描结果以DTB（Device Tree Blob）的格式保存在物理内存中的某个地方。随后 OpenSBI 固件会将其地址保存在 a1 寄存器中，给我们使用。 这个扫描结果描述了所有外设的信息，当中也包括 QEMU 模拟的 RISC-V Virt 计算机中的物理内存。 [info] QEMU 模拟的 RISC-V Virt 计算机中的物理内存 通过查看 QEMU 代码中 hw/riscv/virt.c 的 virt_memmap[] 的定义，可以了解到 QEMU 模拟的 RISC-V Virt 计算机的详细物理内存布局。可以看到，整个物理内存中有不少内存空洞（即含义为 unmapped 的地址空间），也有很多外设特定的地址空间，现在我们看不懂没有关系，后面会慢慢涉及到。目前只需关心最后一块含义为 DRAM 的地址空间，这就是 OS 将要管理的 128 MB 的内存空间。 起始地址 终止地址 含义 0x0 0x100 QEMU VIRT_DEBUG 0x100 0x1000 unmapped 0x1000 0x12000 QEMU MROM 0x12000 0x100000 unmapped 0x100000 0x101000 QEMU VIRT_TEST 0x101000 0x2000000 unmapped 0x2000000 0x2010000 QEMU VIRT_CLINT 0x2010000 0x3000000 unmapped 0x3000000 0x3010000 QEMU VIRT_PCIE_PIO 0x3010000 0xc000000 unmapped 0xc000000 0x10000000 QEMU VIRT_PLIC 0x10000000 0x10000100 QEMU VIRT_UART0 0x10000100 0x10001000 unmapped 0x10001000 0x10002000 QEMU VIRT_VIRTIO 0x10002000 0x20000000 unmapped 0x20000000 0x24000000 QEMU VIRT_FLASH 0x24000000 0x30000000 unmapped 0x30000000 0x40000000 QEMU VIRT_PCIE_ECAM 0x40000000 0x80000000 QEMU VIRT_PCIE_MMIO 0x80000000 0x88000000 DRAM 缺省 128MB，大小可配置 不过为了简单起见，我们并不打算自己去解析这个结果。因为我们知道，QEMU 规定的 DRAM 物理内存的起始物理地址为 0x80000000 。而在 QEMU 中，可以使用 -m 指定 RAM 的大小，默认是 128 MB 。因此，默认的 DRAM 物理内存地址范围就是 [0x80000000, 0x88000000)。 因为后面还会涉及到虚拟地址、物理页和虚拟页面的概念，为了进一步区分而不是简单的只是使用 usize 类型来存储，我们首先建立一个 PhysicalAddress 的类，然后对其实现一系列的 usize 的加、减和输出等等操作，由于这部分实现偏向于 Rust 语法而非 OS，这里不贴出代码，请参考 os/src/memory/address.rs 文件。 然后，我们直接将 DRAM 物理内存结束地址硬编码到内核中，同时因为我们操作系统本身也用了一部分空间，我们也记录下操作系统用到的地址结尾（即 linker script 中的 kernel_end）。 os/src/memory/config.rs lazy_static! { /// 内核代码结束的地址，即可以用来分配的内存起始地址 /// /// 因为 Rust 语言限制，我们只能将其作为一个运行时求值的 static 变量，而不能作为 const pub static ref KERNEL_END_ADDRESS: PhysicalAddress = PhysicalAddress(kernel_end as usize); } extern \"C\" { /// 由 `linker.ld` 指定的内核代码结束位置 /// /// 作为变量存在 [`KERNEL_END_ADDRESS`] fn kernel_end(); } 这里使用了 lazy_static 库，由于 Rust 语言的限制，我们能对编译时 kernel_end 做一个求值然后赋值到 KERNEL_END_ADDRESS 中；所以，lazy_static! 宏帮助我们在第一次使用 lazy_static! 宏包裹的变量时自动完成这些求值工作。 最后，我们在各级文件中加入模块调用，并在 os/src/main.rs 尝试输出。 os/src/main.rs /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { // 初始化各种模块 interrupt::init(); memory::init(); // 注意这里的 KERNEL_END_ADDRESS 为 ref 类型，需要加 * println!(\"{}\", *memory::config::KERNEL_END_ADDRESS); panic!() } 最后运行，可以看到成功显示了我们内核使用的结尾地址 PhysicalAddress(0x8020b220)；注意到这里，你的输出可能因为实现上的细节并不完全一样。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-2/guide/part-3.html":{"url":"docs/lab-2/guide/part-3.html","title":"物理内存管理","keywords":"","body":"物理内存管理 物理页 通常，我们在分配物理内存时并不是以字节为单位，而是以一物理页（Frame），即连续的 4 KB 字节为单位分配。我们希望用物理页号（Physical Page Number，PPN）来代表一物理页，实际上代表物理地址范围在 [PPN×4KB,(PPN+1)×4KB)[\\text{PPN}\\times 4\\text{KB},(\\text{PPN}+1)\\times 4\\text{KB})[PPN×4KB,(PPN+1)×4KB) 的一物理页。 不难看出，物理页号与物理页形成一一映射。为了能够使用物理页号这种表达方式，每个物理页的开头地址必须是 4 KB 的倍数。但这也给了我们一个方便：对于一个物理地址，其除以 4096（或者说右移 12 位）的商即为这个物理地址所在的物理页号。 同样的，我们还是用一个新的结构来封装一下物理页，一是为了和其他类型地址作区分；二是我们可以同时实现一些页帧和地址相互转换的功能。为了后面的方便，我们也把虚拟地址和虚拟页（概念还没有涉及，后面的指导会进一步讲解）一并实现出来，这部分代码请参考 os/src/memory/address.rs。 同时，我们也需要在 os/src/memory/config.rs 中加入相关的设置： os/src/memory/config.rs /// 页 / 帧大小，必须是 2^n pub const PAGE_SIZE: usize = 4096; /// 可以访问的内存区域起始地址 pub const MEMORY_START_ADDRESS: PhysicalAddress = PhysicalAddress(0x8000_0000); /// 可以访问的内存区域结束地址 pub const MEMORY_END_ADDRESS: PhysicalAddress = PhysicalAddress(0x8800_0000); 分配和回收 为了方便管理所有的物理页，我们需要实现一个分配器可以进行分配和回收的操作，在这之前，我们需要先把物理页的概念进行封装。注意到，物理页实际上是一块连续的内存区域，这里我们只是把内存区域的起始物理地址封装到了一个 FrameTracker 里面。 os/src/memory/frame/frame_tracker.rs /// 分配出的物理页 /// /// # `Tracker` 是什么？ /// 太长不看 /// > 可以理解为 [`Box`](alloc::boxed::Box)，而区别在于，其空间不是分配在堆上， /// > 而是直接在内存中划一片（一个物理页）。 /// /// 在我们实现操作系统的过程中，会经常遇到「指定一块内存区域作为某种用处」的情况。 /// 此时，我们说这块内存可以用，但是因为它不在堆栈上，Rust 编译器并不知道它是什么，所以 /// 我们需要 unsafe 地将其转换为 `&'static mut T` 的形式（`'static` 一般可以省略）。 /// /// 但是，比如我们用一块内存来作为页表，而当这个页表我们不再需要的时候，就应当释放空间。 /// 我们其实更需要一个像「创建一个有生命期的对象」一样的模式来使用这块内存。因此， /// 我们不妨用 `Tracker` 类型来封装这样一个 `&'static mut` 引用。 /// /// 使用 `Tracker` 其实就很像使用一个 smart pointer。如果需要引用计数， /// 就在外面再套一层 [`Arc`](alloc::sync::Arc) 就好 pub struct FrameTracker(pub(super) PhysicalPageNumber); impl FrameTracker { /// 帧的物理地址 pub fn address(&self) -> PhysicalAddress { self.0.into() } /// 帧的物理页号 pub fn page_number(&self) -> PhysicalPageNumber { self.0 } } /// 帧在释放时会放回 [`static@FRAME_ALLOCATOR`] 的空闲链表中 impl Drop for FrameTracker { fn drop(&mut self) { FRAME_ALLOCATOR.lock().dealloc(self); } } 这里，我们实现了 FrameTracker 这个结构，而区分于实际在内存中的 4KB 大小的 \"Frame\"，我们设计的初衷是分配器分配给我们 FrameTracker 作为一个帧的标识，而随着\b\b不再需要这个物理页，我们需要回收，我们利用 Rust 的 drop 机制在析构的时候自动实现回收。 最后，我们封装一个物理页分配器，为了符合更 Rust 规范的设计，这个分配器将不涉及任何的具体算法，具体的算法将用一个名为 Allocator 的 Rust trait 封装起来，而我们的 FrameAllocator 会依赖于具体的 trait 实现例化。 os/src/memory/frame/allocator.rs lazy_static! { /// 帧分配器 pub static ref FRAME_ALLOCATOR: Mutex> = Mutex::new(FrameAllocator::new(Range::from( PhysicalPageNumber::ceil(PhysicalAddress::from(*KERNEL_END_ADDRESS))..PhysicalPageNumber::floor(MEMORY_END_ADDRESS), ) )); } /// 基于线段树的帧分配 / 回收 pub struct FrameAllocator { /// 可用区间的起始 start_ppn: PhysicalPageNumber, /// 分配器 allocator: T, } impl FrameAllocator { /// 创建对象 pub fn new(range: impl Into> + Copy) -> Self { FrameAllocator { start_ppn: range.into().start, allocator: T::new(range.into().len()), } } /// 分配帧，如果没有剩余则返回 `Err` pub fn alloc(&mut self) -> MemoryResult { self.allocator .alloc() .ok_or(\"no available frame to allocate\") .map(|offset| FrameTracker(self.start_ppn + offset)) } /// 将被释放的帧添加到空闲列表的尾部 /// /// 这个函数会在 [`FrameTracker`] 被 drop 时自动调用，不应在其他地方调用 pub(super) fn dealloc(&mut self, frame: &FrameTracker) { self.allocator.dealloc(frame.page_number() - self.start_ppn); } } 这个分配器会以一个 PhysicalPageNumber 的 Range 初始化，然后把起始地址记录下来，把整个区间的长度告诉具体的分配器算法，当分配的时候就从算法中取得一个可用的位置作为 offset，再加上起始地址返回回去。 有关具体的算法，我们封装了一个分配器需要的 Rust trait： os/src/algorithm/src/allocator/mod.rs /// 分配器：固定容量，每次分配 / 回收一个元素 pub trait Allocator { /// 给定容量，创建分配器 fn new(capacity: usize) -> Self; /// 分配一个元素，无法分配则返回 `None` fn alloc(&mut self) -> Option; /// 回收一个元素 fn dealloc(&mut self, index: usize); } 并在 os/src/algorithm/src/allocator/ 中分别实现了链表和线段树算法，具体内容可以参考代码。 需要注意，我们使用了 lazy_static! 和 Mutex 来包装分配器，且对于 static mut 类型的修改操作是 unsafe 的。对于静态全局数据，所有的线程都能访问。当一个线程正在访问这段数据的时候，如果另一个线程也来访问，就可能会产生冲突，并带来难以预测的结果。我们在后面的章节会进一步介绍线程和Mutex等概念。 所以我们的方法是使用 spin::Mutex 给这段数据加一把锁，一个线程试图通过 lock() 打开锁来获取内部数据的可变引用，如果钥匙被别的线程所占用，那么这个线程就会一直卡在这里；直到那个占用了钥匙的线程对内部数据的访问结束，锁被释放，将钥匙交还出来，被卡住的那个线程拿到了钥匙，就可打开锁获取内部引用，访问内部数据。 这里使用的是 spin::Mutex，我们需要在 os/Cargo.toml 中添加依赖。幸运的是，它也无需任何操作系统支持（即支持 no_std），我们可以放心使用。 最后，我们把新写的模块加载进来，并在 main 函数中进行简单的测试： os/src/main.rs /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { // 初始化各种模块 interrupt::init(); memory::init(); // 物理页分配 for _ in 0..2 { let frame_0 = match memory::frame::FRAME_ALLOCATOR.lock().alloc() { Result::Ok(frame_tracker) => frame_tracker, Result::Err(err) => panic!(\"{}\", err) }; let frame_1 = match memory::frame::FRAME_ALLOCATOR.lock().alloc() { Result::Ok(frame_tracker) => frame_tracker, Result::Err(err) => panic!(\"{}\", err) }; println!(\"{} and {}\", frame_0.address(), frame_1.address()); } panic!() } 可以看到类似这样的输出： 运行输出 PhysicalAddress(0x80a14000) and PhysicalAddress(0x80a15000) PhysicalAddress(0x80a14000) and PhysicalAddress(0x80a15000) 我们可以看到 frame_0 和 frame_1 会被自动析构然后回收，第二次又分配同样的地址。 思考 运行下面的代码： os/src/main.rs /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { // 初始化各种模块 interrupt::init(); memory::init(); // 物理页分配 match memory::frame::FRAME_ALLOCATOR.lock().alloc() { Result::Ok(frame_tracker) => frame_tracker, Result::Err(err) => panic!(\"{}\", err) }; panic!() 思考，和上面的代码有何不同，我们的设计是否存在一些语法上的设计缺陷？ Click to show 这里的 frame_tracker 变量会在 match 语法里面析构。但是析构的时候，外层的 lock() 函数还没有释放锁，这样写会导致死锁。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-2/guide/summary.html":{"url":"docs/lab-2/guide/summary.html","title":"小结","keywords":"","body":"小结 本章完成了动态分配内存的管理和物理内存的管理，我们通过划分出一段静态内存为操作系统实现了动态内存的分配；通过页的管理模式，实现了物理页的分配器。 本章还只是物理内存的管理，后面为了进一步支持多线程的内存管理，我们将在下一章实现内存的虚拟化。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-3/guide/intro.html":{"url":"docs/lab-3/guide/intro.html","title":"摘要","keywords":"","body":"实验指导三 实验概要 这一章的实验指导中，你将会学到： 虚拟地址和物理地址的概念和关系 利用页表完成虚拟地址到物理地址的映射 实现内核的重映射 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-3/guide/part-1.html":{"url":"docs/lab-3/guide/part-1.html","title":"从虚拟地址到物理地址","keywords":"","body":"从虚拟内存到物理内存 虚拟地址和物理地址 到目前为止，我们简易的操作系统还只是一个内核在执行，还没有多任务的概念。在现代的操作系统中，为了让其他的程序能方便的运行在操作系统上，需要完成的一个很重要的抽象是「每个程序有自己的地址空间，且地址空间范围是一样的」，这将会减少了上层程序的大量麻烦，否则程序本身要维护自己需要的物理内存，这也会导致极大程度的不安全。 这个执行上看到的地址空间，就是虚拟内存。而访问虚拟内存的地址就是虚拟地址（Virtual Address），与之对应的是物理地址（Physical Address）。这样的设计会导致上层的应用程序可能会访问同一个值相等的虚拟地址，所以操作系统需要做的就是替这些程序维护这个虚拟地址到物理地址的映射。甚者，为了统一和连贯，内核自己本身访问内存也将会通过虚拟地址。 我们可以说这个映射的维护是操作系统在做，但是大量频繁的访存不可能全部通过调用操作系统的接口来获取真实的物理地址。所以，这里硬件也会参与，帮我们快速查询操作系统维护的映射，而这个机制就是页表。 如上图所示，这里的图表示了非教学版 rCore 的虚拟地址和物理地址的映射关系。可以看到内核的数据放在了一段高虚拟地址空间，然后会映射到 0x80200000 开始的一段低物理地址空间；而所有的用户程序，将通过操作系统维护的页表映射到不同的物理空间。当然，这只是非教学版 rCore 的设计，在本教程中 kernel layout 和 user layout 会和图有些出入，具体细节可以翻看 linker script。 Sv39 页表的设计和接口会有很多种，这里我们选择 RISC-V 本身硬件支持的 Sv39 模式作为页表的实现。 在 Sv39 模式中，定义物理地址有 56 位，而虚拟地址有 64 位。虽然虚拟地址有 64 位，只有低 39 位有效。不过这不是说高 25 位可以随意取值，规定 63-39 位的值必须等于第 38 位的值，否则会认为该虚拟地址不合法，在访问时会产生异常。 Sv39模式 同样是基于页的，在物理内存那一节曾经提到物理页（Frame）与物理页号（PPN，Physical Page Number）。在这里物理页号为 44 位，每个物理页大小为 4KB。同理，我们对于虚拟内存定义虚拟页（Page）以及虚拟页号（VPN, Virtual Page Number) 。在这里虚拟页号为 27 位，每个虚拟页大小也为 4KB。物理地址和虚拟地址的最后 12 位都表示页内偏移，即表示该地址在所在物理页（虚拟页）上的什么位置。 虚拟地址到物理地址的映射以页为单位，也就是说把虚拟地址所在的虚拟页映射到一个物理页，然后再在这个物理页上根据页内偏移找到物理地址，从而完成映射。我们要实现虚拟页到物理页的映射，由于虚拟页与虚拟页号一一对应，物理页帧与物理页号一一对应，本质上我们要实现虚拟页号到物理页号的映射，而这就是页表所做的事情。 页表项 一个页表项（PTE，Page Table Entry）是用来描述一个虚拟页号如何映射到物理页号的。如果一个虚拟页号通过某种手段找到了一个页表项，并通过读取上面的物理页号完成映射，我们称这个虚拟页号通过该页表项完成映射的。 我们可以看到 Sv39 模式里面的一个页表项大小为 64 位（即 8 字节）。其中第 53-10 共 44 位为一个物理页号，表示这个虚拟页号映射到的物理页号。后面的第 9-0 位则描述页的相关状态信息。 V 表示这个页表项是否合法。如果为 0 表示不合法，此时页表项其他位的值都会被忽略。 R,W,X 分别表示是否可读（Readable）、可写（Writable）和可执行（Executable）。 以 W 这一位为例，如果为零表示不可写，那么如果一条 store 的指令，它通过这个页表项完成了虚拟页号到物理页号的映射，找到了物理地址。但是仍然会报出异常，是因为这个页表项规定如果物理地址是通过它映射得到的，执行的行为和页表描述的状态并不一致。 同时，根据 R,W,X 取值的不同，我们还有一些特别表示和约定： 也就是说，如果 R,W,X 均为 0，文档上说这表示这个页表项指向下一级页表，我们先暂时记住就好。 U 为 1 表示用户态运行的程序可以通过该页表项完成地址映射。事实上用户态运行的程序也只能够通过 U 为 1 的页表项进行虚实地址映射。 然而，我们所处在的 S 态也并不是理所当然的可以访问通过这些 U 为 1 的页表项进行映射的用户态内存空间。我们需要将 S 态的状态寄存器 sstatus 上的 SUM (permit Supervisor User Memory access) 位手动设置为 1 才可以做到这一点。否则S 态通过 的load/store等指令在访问U 为 1 的页表项映射的用合同内存空间时，CPU会报出异常。 A 表示 Accessed，如果为 1 则表示自从上次 A 被清零后，有虚拟地址通过这个页表项进行读写。 D 表示 Dirty，如果为 1 表示自从上次 D 被清零后，有虚拟地址通过这个页表项进行写入。 RSW 两位留给 S 态的程序来进行拓展功能实现。 多级页表 一个虚拟页号要通过某种手段找到页表项，那么要怎么才能找到呢？ 想一种最为简单粗暴的方法，在物理内存中开一个大数组作为页表，把所有虚拟页号对应的页表项都存下来。在找的时候根据虚拟页号来索引页表项。即，假设大数组开头的物理地址为 a，虚拟页号为 VPN\\text{VPN}VPN，则该虚拟页号对应的页表项的物理地址为 a+VPN×8a+\\text{VPN}\\times8a+VPN×8（每个页表项 8 字节）。 但是这样会花掉我们大量的内存空间。我们目前只有可怜的 128MB 内存，即使我们有足够的内存也不应该这样去浪费。这是由于有很多虚拟地址我们根本没有用到，因此他们对应的虚拟页号不需要映射，我们浪费了很多无用的内存。 事实上，在 Sv39 模式中我们采用三级页表，即将 27 位的虚拟页号分为三个等长的部分，第 26-18 位为三级索引 VPN2\\text{VPN}_2VPN​2​​，第 17-9 位为二级索引 VPN1\\text{VPN}_1VPN​1​​，第 8-0 位为一级索引 VPN0\\text{VPN}_0VPN​0​​。 我们也将页表分为三级页表，二级页表，一级页表。每个页表都用 9 位索引的，因此有 29=5122^{9}=5122​9​​=512 个页表项，而每个页表项都是 8 字节，因此每个页表大小都为 512×8=4KB512\\times 8=4\\text{KB}512×8=4KB。正好是一个物理页的大小。我们可以把一个页表放到一个物理页中，并用一个物理页号来描述它。事实上，三级页表的每个页表项中的物理页号可描述一个二级页表；二级页表的每个页表项中的物理页号可描述一个一级页表；一级页表中的页表项内容则和我们刚才提到的页表项一样，其内容包含物理页号，即描述一个要映射到的物理页。 具体来说，假设我们有虚拟地址 (VPN2,VPN1,VPN0,offset)(\\text{VPN}_2, \\text{VPN}_1, \\text{VPN}_0, \\text{offset})(VPN​2​​,VPN​1​​,VPN​0​​,offset)： 我们首先会记录装载「当前所用的三级页表的物理页」的页号到 satp 寄存器中； 把 VPN2\\text{VPN}_2VPN​2​​ 作为偏移在三级页表的物理页中找到第二级页表的物理页号； 把 VPN1\\text{VPN}_1VPN​1​​ 作为偏移在二级页表的物理页中找到第一级页表的物理页号； 把 VPN0\\text{VPN}_0VPN​0​​ 作为偏移在一级页表的物理页中找到要访问位置的物理页号； 物理页号对应的物理页基址加上 offset\\text{offset}offset 就是虚拟地址对应的物理地址。 上述流程也可以用下图表（来源于MIT 6.828课程）示： 我们通过这种复杂的手段，终于从虚拟页号找到了一级页表项，从而得出了物理页号。刚才我们提到若页表项满足 R,W,X 都为 0，表明这个页表项指向下一级页表。在这里三级和二级页表项的 R,W,X 为 0 应该成立，因为它们指向了下一级页表。 然而三级和二级页表项不一定要指向下一级页表。我们知道每个一级页表项控制一个虚拟页号，即控制 4KB 虚拟内存；每个二级页表项则控制 9 位虚拟页号，总计控制 4KB×29=2MB4\\text{KB}\\times 2^9=2\\text{MB}4KB×2​9​​=2MB 虚拟内存；每个三级页表项控制 18 位虚拟页号，总计控制 2MB×29=1GB2\\text{MB}\\times 2^9=1\\text{GB}2MB×2​9​​=1GB 虚拟内存。我们可以将二级页表项的 R,W,X 设置为不是全 0 的，那么它将与一级页表项类似，只不过可以映射一个 2MB 的大页（Huge Page）。同理，也可以将三级页表项看作一个叶子，来映射一个 1GB 的大页。这样在RISC-V中，可以很方便地建立起大页机制。 页表基址 页表的基址（起始地址）一般会保存在一个特殊的寄存器中。在 RISC-V 中，这个特殊的寄存器就是页表寄存器 satp。 我们使用寄存器 satp 来控制 CPU 进行页表映射。 MODE 控制 CPU 使用哪种页表实现，我们只需将 MODE 设置为 8 即表示 CPU 使用 Sv39 。 ASID 表示地址空间标识符，这里还没有涉及到进程的概念，我们不需要管这个地方。 PPN 存的是三级页表所在的物理页号。这样，给定一个虚拟页号，CPU 就可以从三级页表开始一步步的将其映射到一个物理页号。 于是，OS 可以在内存中为不同的应用分别建立不同虚实映射的页表，并通过修改寄存器 satp 的值指向不同的页表，从而可以修改 CPU 虚实地址映射关系及内存保护的行为。 快表（TLB） 我们知道，物理内存的访问速度要比 CPU 的运行速度慢很多。如果我们按照页表机制循规蹈矩的一步步走，将一个虚拟地址转化为物理地址需要访问 3 次物理内存，得到物理地址后还需要再访问一次物理内存，才能完成访存。这无疑很大程度上降低了效率。 事实上，实践表明虚拟地址的访问具有时间局部性和空间局部性。因此，在 CPU 内部，我们使用快表（TLB, Translation Lookaside Buffer）来作为虚拟页号到物理页号的映射的缓存。这部分知识在计算机组成原理课程中有所体现，当我们要做一个映射时，会有很大可能这个映射在近期被完成过，所以我们可以先到 TLB 里面去查一下，如果有的话我们就可以直接完成映射，而不用访问那么多次内存了。 但如果修改了 satp 寄存器，说明OS切换到了一个与先前映射方式完全不同的页表。此时快表里面存储的映射已经失效了，这种情况下OS要在修改satp的指令后面马上使用 sfence.vma 指令刷新整个 TLB。 同样，我们手动修改一个页表项之后，也修改了映射，但 TLB 并不会自动刷新，我们也需要使用 sfence.vma 指令刷新 TLB。如果不加参数的，sfence.vma 会刷新整个 TLB。你可以在后面加上一个虚拟地址，这样 sfence.vma 只会刷新这个虚拟地址的映射。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-3/guide/part-2.html":{"url":"docs/lab-3/guide/part-2.html","title":"修改内核","keywords":"","body":"修改内核 之前的内核实现并未使能页表机制，实际上内核是直接在物理地址空间上运行的。这样虽然比较简单，但是为了后续能够支持多个用户进程能够在内核中并发运行，满足隔离等性质，我们要先运用学过的页表知识，把内核的运行环境从物理地址空间转移到虚拟地址空间，为之后的功能打好铺垫。 更具体的，我们现在想将内核代码放在虚拟地址空间中以 0xffffffff80200000 开头的一段高地址空间中。这意味着原来放在 0x80200000 起始地址的全部内核结构被平移到了 0xffffffff80200000 的地址上，即映射关系为：虚拟地址减去偏移量 0xffffffff00000000 == 原来的物理地址。当然，这种线性平移并不是唯一的映射方式，但是至少现在，内核的全部代码/数据所在的虚拟空间和物理空间是这样的线性映射。 所以需要把原来的 linker script 和之前在物理内存管理上的一些参数修改一下。 os/src/linker.ld /* Linker Script 语法可以参见：http://www.scoberlin.de/content/media/http/informatik/gcc_docs/ld_3.html */ /* 目标架构 */ OUTPUT_ARCH(riscv) /* 执行入口 */ ENTRY(_start) /* 数据存放起始地址 */ BASE_ADDRESS = 0xffffffff80200000; /* 修改为虚拟地址 */ SECTIONS { /* . 表示当前地址（location counter） */ . = BASE_ADDRESS; /* start 符号表示全部的开始位置 */ kernel_start = .; /* 加入对齐 */ . = ALIGN(4K); text_start = .; /* .text 字段 */ .text : { /* 把 entry 函数放在最前面 */ *(.text.entry) /* 要链接的文件的 .text 字段集中放在这里 */ *(.text .text.*) } /* 加入对齐 */ . = ALIGN(4K); rodata_start = .; /* .rodata 字段 */ .rodata : { /* 要链接的文件的 .rodata 字段集中放在这里 */ *(.rodata .rodata.*) } /* 加入对齐 */ . = ALIGN(4K); data_start = .; /* .data 字段 */ .data : { /* 要链接的文件的 .data 字段集中放在这里 */ *(.data .data.*) } /* 加入对齐 */ . = ALIGN(4K); bss_start = .; /* .bss 字段 */ .bss : { /* 要链接的文件的 .bss 字段集中放在这里 */ *(.sbss .bss .bss.*) } /* 结束地址 */ /* 加入对齐 */ . = ALIGN(4K); kernel_end = .; } 首先，对于 linker script，我们把放置的基地址修改为了虚拟地址，另外还有一些修改是我们把每个数据段都对齐到了 4KB，一个 4KB 的虚拟页中不会包含两个段，这意味着这个页的属性是可以确定的。举个例子，如果不对齐的话，只读的 .rodata 和 .data 段可能放在一个页中，但是页表中需要写上诸如是否可写的属性，这时候就必须分开才可以标注属性。 对应修改 os/src/memory/config.rs 中的 KERNEL_END_ADDRESS 修改为虚拟地址并加入偏移量： os/src/memory/config.rs lazy_static! { /// 内核代码结束的地址，即可以用来分配的内存起始地址 /// /// 因为 Rust 语言限制，我们只能将其作为一个运行时求值的 static 变量，而不能作为 const pub static ref KERNEL_END_ADDRESS: VirtualAddress = VirtualAddress(kernel_end as usize); } /// 内核使用线性映射的偏移量 pub const KERNEL_MAP_OFFSET: usize = 0xffff_ffff_0000_0000; 和上一章类似，我们也对虚拟地址和虚拟页号这两个类进行了封装，同时也支持了一些诸如 VirtualAddress::from(PhysicalAddress) 的转换 trait（即一些加减偏移量等操作），这部分实现更偏向于 Rust 语法，这里不再赘述实现方法，想去了解实现时可以参考 os/src/memory/address.rs。 最后一步，我们需要告诉 RISC-V CPU 我们做了这些修改，也就是需要在启动时、在进入 rust_main 之前我们要完成一个从物理地址访存模式到虚拟访存模式的转换，同时这也意味着，我们要写一个简单的页表，完成这个线性映射： os/src/entry.asm # 操作系统启动时所需的指令以及字段 # # 我们在 linker.ld 中将程序入口设置为了 _start，因此在这里我们将填充这个标签 # 它将会执行一些必要操作，然后跳转至我们用 rust 编写的入口函数 # # 关于 RISC-V 下的汇编语言，可以参考 https://github.com/riscv/riscv-asm-manual/blob/master/riscv-asm.md # %hi 表示取 [12,32) 位，%lo 表示取 [0,12) 位 .section .text.entry .globl _start # 目前 _start 的功能：将预留的栈空间写入 $sp，然后跳转至 rust_main _start: # 计算 boot_page_table 的物理页号 lui t0, %hi(boot_page_table) li t1, 0xffffffff00000000 sub t0, t0, t1 srli t0, t0, 12 # 8 0x8000_0000，0xcf 表示 VRWXAD 均为 1 .quad (0x80000 0x8000_0000，0xcf 表示 VRWXAD 均为 1 .quad (0x80000 回顾一下，当 OpenSBI 启动完成之后，我们面对的是一个怎样的局面： 物理内存状态中 OpenSBI 代码放在 [0x80000000,0x80200000) 中，内核代码放在以 0x80200000 开头的一块连续物理内存中； CPU 状态：处于 S Mode ，寄存器 satp 的 MODE 字段被设置为 Bare 模式，即无论取指还是访存我们通过物理地址直接访问物理内存。PC 即为 0x80200000 指向内核的第一条指令； 栈指针寄存器 sp 还没有初始化，还没有指向 boot_stack_top； 代码中 boot_stack_top 等符号的地址都是虚拟地址（高地址）。 而我们需要做的就是，把 CPU 的访问模式改为 Sv39，这里需要做的就是把一个页表的物理页号和 Sv39 模式写入 satp 寄存器，然后刷新 TLB。 我们先使用一种最简单的页表构造方法，还记得上一节中所讲的大页吗？那时我们提到，将一个三级页表项的标志位 R,W,X 不设为全 0，可以将它变为表示 1GB 的一个大页。 那么，页表里面需要放什么数据呢？第二个 .quad （表中第 510 项，510 的二进制是要索引虚拟地址的 VPN3VPN_3VPN​3​​）显然是从 0xffffffff80000000 到 0x80000000 这样的线性映射，同时 0xcf 表示了 VRWXAD 均为 1 的属性。 观察一下，除了上面这个映射，我们的 boot_page_table 里面为什么还有一个从 0x80000000 到 0x80000000 的映射？ Click to show 这是因为，在跳转到 rust_main 之前（即 jr t0）之前，PC 的值都还是 0x802xxxxx 这样的地址，即使是写入了 satp 寄存器，但是 PC 的地址不会变。为了执行这段中间的尴尬的代码，我们在页表里面也需要加入这段代码的地址的映射。 那为什么跳转之后就没有问题了呢？这是因为 rust_main 这个符号本身是高虚拟地址（这点在 linker script 里面已经体现了）。 为什么我把这个映射删了，代码还是可以运行？因为 QEMU 有指令缓存，实际上这样的删去的写法是错误的。 这个尴尬的映射会对后面产生错误的影响吗？不会，因为在后面，我们将使用 Rust 而不是汇编把新的页表加载到 satp 里面，这个页表只是启动时的一个简单页表，或者我们可以叫它“内核初始映射”，后面我们会加入更细致的映射，把不同的段根据属性放在不同的页面里面。 刷新之后，我们加载完栈地址，就可以跳转到 Rust 编写的函数中了。至此，我可以在主函数中做些简单的输出，我们重新编译（cargo 不会感知 linker script 的变化，可能需要 cargo clean）并运行，正确的结果应该是我们可以看到这些输出，虽然这和上一个章节的结果看上去没什么两样，但是现在内核的运行已经在虚拟地址空间了。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-3/guide/part-3.html":{"url":"docs/lab-3/guide/part-3.html","title":"实现页表","keywords":"","body":"实现页表 为了实现 Sv39 页表，我们的思路是把一个分配好的物理页（即会自动销毁的 FrameTracker）拿来把数据填充作为页表，而页表中的每一项是一个 8 字节的页表项。 对于页表项的位级别的操作，首先需要加入两个关于位操作的 crate： os/Cargo.toml bitflags = \"1.2.1\" bit_field = \"0.10.0\" 然后，首先了构建了通过虚拟页号获得三级 VPN 的函数： os/src/memory/address.rs impl VirtualPageNumber { /// 得到一、二、三级页号 pub fn levels(self) -> [usize; 3] { [ self.0.get_bits(18..27), self.0.get_bits(9..18), self.0.get_bits(0..9), ] } } 页表项 后面，我们来实现页表项，其实就是对一个 usize（8 字节）的封装，同时我们可以用刚刚加入的 bit 级别操作的 crate 对其实现一些取出特定段的方便后续实现的函数： os/src/memory/mapping/page_table_entry.rs /// Sv39 结构的页表项 #[derive(Copy, Clone, Default)] pub struct PageTableEntry(usize); impl PageTableEntry { /// 将相应页号和标志写入一个页表项 pub fn new(page_number: PhysicalPageNumber, flags: Flags) -> Self { Self( *0usize .set_bits(..8, flags.bits() as usize) .set_bits(10..54, page_number.into()), ) } /// 获取页号 pub fn page_number(&self) -> PhysicalPageNumber { PhysicalPageNumber::from(self.0.get_bits(10..54)) } /// 获取地址 pub fn address(&self) -> PhysicalAddress { PhysicalAddress::from(self.page_number()) } /// 获取标志位 pub fn flags(&self) -> Flags { unsafe { Flags::from_bits_unchecked(self.0.get_bits(..8) as u8) } } /// 是否为空（可能非空也非 Valid） pub fn is_empty(&self) -> bool { self.0 == 0 } } impl core::fmt::Debug for PageTableEntry { fn fmt(&self, formatter: &mut core::fmt::Formatter) -> core::fmt::Result { formatter .debug_struct(\"PageTableEntry\") .field(\"value\", &self.0) .field(\"page_number\", &self.page_number()) .field(\"flags\", &self.flags()) .finish() } } bitflags! { /// 页表项中的 8 个标志位 #[derive(Default)] pub struct Flags: u8 { /// 有效位 const VALID = 1 页表 有了页表项，512 个连续的页表项组成的 4KB 物理页，同时再加上一些诸如多级添加映射的功能，就可以封装为页表。 os/src/memory/mapping/page_table.rs /// 存有 512 个页表项的页表 /// /// 注意我们不会使用常规的 Rust 语法来创建 `PageTable`。相反，我们会分配一个物理页， /// 其对应了一段物理内存，然后直接把其当做页表进行读写。我们会在操作系统中用一个「指针」 /// [`PageTableTracker`] 来记录这个页表。 #[repr(C)] pub struct PageTable { pub entries: [PageTableEntry; PAGE_SIZE / 8], } impl PageTable { /// 将页表清零 pub fn zero_init(&mut self) { self.entries = [Default::default(); PAGE_SIZE / 8]; } } 然而，我们不会把这个巨大的数组在函数之间不停传递，我们这里的思路也同样更多利用 Rust 的特性，所以做法是利用一个 PageTableTracker 的结构对 FrameTracker 封装，但是里面的行为是对 FrameTracker 记录的物理页当成 PageTable 进行操作。同时，这个 PageTableTracker 和 PageTableEntry 也通过一些 Rust 中的自动解引用的特性为后面的实现铺平了道路，比如我们可以直接把 PageTableTracker 当成 PageTable 对待，同时，如果一个 PageTableEntry 指向的是另一个 PageTable 我们可以直接方便的让编译器自动完成这些工作。 os/src/memory/mapping/page_table.rs /// 类似于 [`FrameTracker`]，用于记录某一个内存中页表 /// /// 注意到，「真正的页表」会放在我们分配出来的物理页当中，而不应放在操作系统的运行栈或堆中。 /// 而 `PageTableTracker` 会保存在某个线程的元数据中（也就是在操作系统的堆上），指向其真正的页表。 /// /// 当 `PageTableTracker` 被 drop 时，会自动 drop `FrameTracker`，进而释放帧。 pub struct PageTableTracker(pub FrameTracker); impl PageTableTracker { /// 将一个分配的帧清零，形成空的页表 pub fn new(frame: FrameTracker) -> Self { let mut page_table = Self(frame); page_table.zero_init(); page_table } /// 获取物理页号 pub fn page_number(&self) -> PhysicalPageNumber { self.0.page_number() } } 至此，我们完成了物理页中的页表。后面，我们将把内核中各个段做一个更精细的映射，把之前的那个粗糙的初始映射页表替换掉。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-3/guide/part-4.html":{"url":"docs/lab-3/guide/part-4.html","title":"实现内核重映射","keywords":"","body":"实现内核重映射 在上文中，我们虽然构造了一个简单映射使得内核能够运行在虚拟空间上，但是这个映射是比较粗糙的。 我们知道一个程序通常含有下面几段： .text 段：存放代码，需要可读、可执行的，但不可写； .rodata 段：存放只读数据，顾名思义，需要可读，但不可写亦不可执行； .data 段：存放经过初始化的数据，需要可读、可写； .bss 段：存放零初始化的数据，需要可读、可写。 我们看到各个段之间的访问权限是不同的。在现在的映射下，我们甚至可以修改内核 .text 段的代码。因为我们通过一个标志位 W 为 1 的页表项完成映射。 因此，我们考虑对这些段分别进行重映射，使得他们的访问权限被正确设置。 这个需求可以抽象为一段内存（可能是很多个虚拟页）通过一个方式映射到很多个物理页上，同时这个内存段将会有一个统一的属性和进一步高层次的管理。 举个例子，在内核的代码段中 .bss 段可能不止会占用一个页面，而是很多页面，我们需要把全部的这些页面以线性的形式映射到一个位置。同时整个这些页面构成的内存段将会有统一的属性交由内核来管理。 下面，我们首先来封装内存段的概念。 内存段 Segment 正如上面说的，内存段是一篇连续的虚拟页范围，其中的每一页通过线性映射（直接偏移到一个物理页）或者分配（其中的每个虚拟页调用物理页分配器分配一个物理页）。线性映射出现在内核空间中；而为了支持每个用户进程看到的虚拟空间是一样的，我们不能全都用线性映射，所以基于页分配的方式会出现在用户这种情景下。如果你还是不明白，可以去翻看一下本章的「虚拟地址到物理地址」一个小节中非教学版 rCore 的映射图。 下面，我们用 enum 和 struct 来封装内存段映射的类型和内存段本身： os/src/memory/mapping/segment.rs /// 映射的类型 #[derive(Debug)] pub enum MapType { /// 线性映射，操作系统使用 Linear, /// 按帧分配映射 Framed, } /// 一个映射片段（对应旧 tutorial 的 `MemoryArea`） #[derive(Debug)] pub struct Segment { /// 映射类型 pub map_type: MapType, /// 所映射的虚拟地址 pub page_range: Range, /// 权限标志 pub flags: Flags, } 后面，上层需要做的是把一个 Segment 中没有建立物理页映射关系的全部虚拟页，都申请到物理页并建立映射关系（或者说线性映射没有这样的虚拟页，而分配映射需要把每个虚拟页都申请一个对应的物理页）。 于是我们可以实现这样一个需要具体分配的迭代器： os/src/memory/mapping/segment.rs impl Segment { /// 遍历对应的物理地址（如果可能） pub fn iter_mapped(&self) -> Option> { match self.map_type { // 线性映射可以直接将虚拟地址转换 MapType::Linear => Some(self.iter().map(PhysicalPageNumber::from)), // 按帧映射无法直接获得物理地址，需要分配 MapType::Framed => None, } } } Mapping 有了页表、内存段，我们对这两个进行组合和封装，借助其中对页表的操作实现对内存段的映射，或者也可以说这里的结构是对上一小节的页表的进一步的从单级到三级的封装，需要记录根页表和对其中申请的页表进行追踪来控制何时释放空间。 os/src/memory/mapping/mapping.rs #[derive(Default)] /// 某个线程的内存映射关系 pub struct Mapping { /// 保存所有使用到的页表 page_tables: Vec, /// 根页表的物理页号 root_ppn: PhysicalPageNumber, } impl Mapping { /// 创建一个有根节点的映射 pub fn new() -> MemoryResult { let root_table = PageTableTracker::new(FRAME_ALLOCATOR.lock().alloc()?); let root_ppn = root_table.page_number(); Ok(Mapping { page_tables: vec![root_table], root_ppn, }) } } 后面，实现对页表的查找，并利用该函数实现对虚拟页号到物理页号的映射： os/src/memory/mapping/mapping.rs: impl Mapping确定虚拟页到哪个 /// 找到给定虚拟页号的三级页表项 /// /// 如果找不到对应的页表项，则会相应创建页表 pub fn find_entry(&mut self, vpn: VirtualPageNumber) -> MemoryResult { // 从根页表开始向下查询 // 这里不用 self.page_tables[0] 避免后面产生 borrow-check 冲突（我太菜了） let root_table: &mut PageTable = PhysicalAddress::from(self.root_ppn).deref_kernel(); let mut entry = &mut root_table.entries[vpn.levels()[0]]; // println!(\"[{}] = {:x?}\", vpn.levels()[0], entry); for vpn_slice in &vpn.levels()[1..] { if entry.is_empty() { // 如果页表不存在，则需要分配一个新的页表 let new_table = PageTableTracker::new(FRAME_ALLOCATOR.lock().alloc()?); let new_ppn = new_table.page_number(); // 将新页表的页号写入当前的页表项 *entry = PageTableEntry::new(new_ppn, Flags::VALID); // 保存页表 self.page_tables.push(new_table); } // 进入下一级页表（使用偏移量来访问物理地址） entry = &mut entry.get_next_table().entries[*vpn_slice]; } // 此时 entry 位于第三级页表 Ok(entry) } /// 为给定的虚拟 / 物理页号建立映射关系 fn map_one( &mut self, vpn: VirtualPageNumber, ppn: PhysicalPageNumber, flags: Flags, ) -> MemoryResult { // 定位到页表项 let entry = self.find_entry(vpn)?; assert!(entry.is_empty(), \"virtual address is already mapped\"); // 页表项为空，则写入内容 *entry = PageTableEntry::new(ppn, flags); Ok(()) } 有了 map_one 来实现一个虚拟页对物理页的映射，我们就可以实现对一个连续的 Segment 的映射： os/src/memory/mapping/mapping.rs: impl Mapping /// 加入一段映射，可能会相应地分配物理页面 /// /// - `init_data` /// 复制一段内存区域来初始化新的内存区域，其长度必须等于 `segment` 的大小。 /// /// /// 未被分配物理页面的虚拟页号暂时不会写入页表当中，它们会在发生 PageFault 后再建立页表项。 pub fn map( &mut self, segment: &Segment, ) -> MemoryResult> { // segment 可能可以内部做好映射 if let Some(ppn_iter) = segment.iter_mapped() { // segment 可以提供映射，那么直接用它得到 vpn 和 ppn 的迭代器 println!(\"map {:x?}\", segment.page_range); for (vpn, ppn) in segment.iter().zip(ppn_iter) { self.map_one(vpn, ppn, segment.flags)?; } Ok(vec![]) } else { // 需要再分配帧进行映射 // 记录所有成功分配的页面映射 let mut allocated_pairs = vec![]; for vpn in segment.iter() { let frame: FrameTracker = FRAME_ALLOCATOR.lock().alloc()?; println!(\"map {:x?} -> {:x?}\", vpn, frame.page_number()); self.map_one(vpn, frame.page_number(), segment.flags)?; allocated_pairs.push((vpn, frame)); } Ok(allocated_pairs) } } 最后，我们实现一个函数实现页表的激活，也就是把 satp 寄存器更新并刷新 TLB： os/src/memory/mapping/mapping.rs: impl Mapping /// 将当前的映射加载到 `satp` 寄存器 pub fn activate(&self) { // satp 低 27 位为页号，高 4 位为模式，8 表示 Sv39 let new_satp = self.root_ppn.0 | (8 MemorySet 最后，我们需要把内核的每个段根据不同的属性写入上面的封装的 Mapping 中，并把它作为一个新的结构 MemorySet 给后面的线程的概念使用，这意味着：每个线程（到目前为止你可以大致理解为自己电脑中的同时工作的应用程序们）将会拥有一个 MemorySet ，其中存的将会是「它看到的虚拟内存空间分成的内存段」和「这些段中包含的虚拟页到物理页的映射」： os/src/memory/mapping/memory_set.rs /// 一个线程所有关于内存空间管理的信息 pub struct MemorySet { /// 维护页表和映射关系 pub mapping: Mapping, /// 每个字段 pub segments: Vec, } 到目前为止，我们还只有内核这个概念，所以我们只是实现一个内核的精细映射来代替开始的时候粗糙的权限管理（一并把页表激活实现）： os/src/memory/mapping/memory_set.rs impl MemorySet { /// 创建内核重映射 pub fn new_kernel() -> MemoryResult { // 在 linker.ld 里面标记的各个字段的起始点，均为 4K 对齐 extern \"C\" { fn text_start(); fn rodata_start(); fn data_start(); fn bss_start(); } // 建立字段 let segments = vec![ // .text 段，r-x Segment { map_type: MapType::Linear, page_range: Range::::from( (text_start as usize)..(rodata_start as usize), ) .into(), flags: Flags::VALID | Flags::READABLE | Flags::EXECUTABLE, }, // .rodata 段，r-- Segment { map_type: MapType::Linear, page_range: Range::::from( (rodata_start as usize)..(data_start as usize), ) .into(), flags: Flags::VALID | Flags::READABLE, }, // .data 段，rw- Segment { map_type: MapType::Linear, page_range: Range::::from( (data_start as usize)..(bss_start as usize), ) .into(), flags: Flags::VALID | Flags::READABLE | Flags::WRITABLE, }, // .bss 段，rw- Segment { map_type: MapType::Linear, page_range: Range::from( VirtualAddress::from(bss_start as usize)..*KERNEL_END_ADDRESS, ), flags: Flags::VALID | Flags::READABLE | Flags::WRITABLE, }, // 剩余内存空间，rw- Segment { map_type: MapType::Linear, page_range: Range::from( *KERNEL_END_ADDRESS..VirtualAddress::from(MEMORY_END_ADDRESS), ), flags: Flags::VALID | Flags::READABLE | Flags::WRITABLE, }, ]; let mut mapping = Mapping::new()?; // 准备保存所有新分配的物理页面 let mut allocated_pairs: Box> = Box::new(core::iter::empty()); // 每个字段在页表中进行映射 for segment in segments.iter() { let new_pairs = mapping.map(segment)?; // 同时将新分配的映射关系保存到 allocated_pairs 中 allocated_pairs = Box::new(allocated_pairs.chain(new_pairs.into_iter())); } Ok(MemorySet { mapping, segments }) } /// 替换 `satp` 以激活页表 /// /// 如果当前页表就是自身，则不会替换，但仍然会刷新 TLB。 pub fn activate(&self) { self.mapping.activate() } } 到这里，我们完整实现了内核的重映射，最后可以在主函数中测试一下： os/src/main.rs /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { // 初始化各种模块 interrupt::init(); memory::init(); let remap = memory::mapping::MemorySet::new_kernel().unwrap(); remap.activate(); println!(\"kernel remapped\"); panic!() } 在这里我们申请了一个内核的重映射，然后对页表进行激活，后面运行了一句输出，虽然看起来没有什么不同，只是输出了一句话，但是需要注意到这句话所用的所有逻辑已经建立在了新构建的页表上，而不是那个粗糙的 boot_page_table 了。boot_page_table 并非没有用，它为我们构建重映射提供了支持，但终究我们会用更精细的页表和映射代替了它，实现了更细致的管理和安全性。 至此，我们实现了重映射，而在上面我们也只是用一个局部变量来调用了简单测试了这个映射，而实际上，后面我们会把全部运行的逻辑都封装为线程，每个线程将会有一个 MemorySet 并存在于一个线程的结构中而不是一个简单的局部变量。当线程销毁的时候，线程中全部使用的逻辑（包括页表所在的物理页和其他申请的物理页等）将会被之前设计的 Tracker 机制自动释放。 不得不说，用 Rust 写这些内容是痛苦的（可能后面一两个章节还会痛苦一段时间），但是为了充分发挥 Rust 的特性，这些挣扎是必要的，一旦我们铺平了这些基础设施，后面的流程会大大简化。对于这两章的内容我们也经历过大量讨论，也做了大量的设计性和教学性权衡，如果你阅读文档还是一头雾水，可以去完整的阅读代码和对应的注释并尝试运行。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-3/guide/summary.html":{"url":"docs/lab-3/guide/summary.html","title":"小结","keywords":"","body":"小结 回顾本章，我们理清了虚拟地址和物理地址的概念和关系；并利用页表完成虚拟地址到物理地址的映射；最后实现了内核空间段的重映射。 如果说本章和前一个章节是对空间的划分和管理，那么在下一个小节中，我们将实现对时间的划分和管理，也就是线程。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-4/guide/intro.html":{"url":"docs/lab-4/guide/intro.html","title":"摘要","keywords":"","body":"实验指导四 实验概要 这一章的实验指导中，你将会学到： 线程和进程的概念以及运行状态的表示 线程的切换 对 CPU 进行抽象在上面完成对线程的调度 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-4/guide/part-1.html":{"url":"docs/lab-4/guide/part-1.html","title":"线程和进程","keywords":"","body":"线程和进程 基本概念 从源代码经过编译器一系列处理（编译、链接、优化等）得到的可执行文件，我们称为程序（Program）。而通俗地说，进程（Process）就是正在运行并使用计算机资源的程序，与放在磁盘中一动不动的程序不同：首先，进程得到了操作系统提供的资源：程序的代码、数据段被加载到内存中，程序所需的虚拟内存空间被真正构建出来。同时操作系统还给进程分配了程序所要求的各种其他资源，如我们上面几个章节中提到过的页表、文件的资源。 然而如果仅此而已，进程还尚未体现出其“正在运行”的动态特性。而正在运行意味着 CPU 要去执行程序代码段中的代码，为了能够进行函数调用，我们还需要运行栈（Stack）。 出于OS对计算机系统精细管理的目的，我们通常将“正在运行”的动态特性从进程中剥离出来，这样的一个借助 CPU 和栈的执行流，我们称之为线程 (Thread) 。一个进程可以有多个线程，也可以如传统进程一样只有一个线程。 这样，进程虽然仍是代表一个正在运行的程序，但是其主要功能是作为资源的分配单位，管理页表、文件、网络等资源。而一个进程的多个线程则共享这些资源，专注于执行，从而作为执行的调度单位。举一个例子，为了分配给进程一段内存，我们把一整个页表交给进程，而出于某些目的（比如为了加速需要两个线程放在两个 CPU 的核上），我们需要线程的概念来进一步细化执行的方式，这时进程内部的全部这些线程看到的就是同样的页表，看到的也是相同的地址。但是需要注意的是，这些线程为了可以独立运行，有自己的栈（会放在相同地址空间的不同位置），CPU 也会以它们这些线程为一个基本调度单位。 线程的表示 在不同操作系统中，为每个线程所保存的信息都不同。在这里，我们提供一种基础的实现，每个线程会包括： 线程 ID：用于唯一确认一个线程，它会在系统调用等时刻用到。 运行栈：每个线程都必须有一个独立的运行栈，保存运行时数据。 线程执行上下文：当线程不在执行时，我们需要保存其上下文（其实就是一堆寄存器的值），这样之后才能够将其恢复，继续运行。和之前实现的中断一样，上下文由 Context 类型保存。（注：这里的线程执行上下文与前面提到的中断上下文是不同的概念） 所属进程的记号：同一个进程中的多个线程，会共享页表、打开文件等信息。因此，我们将它们提取出来放到线程中。 内核栈：除了线程运行必须有的运行栈，中断处理也必须有一个单独的栈。之前，我们的中断处理是直接在原来的栈上进行（我们直接将 Context 压入栈）。但是在后面我们会引入用户线程，这时就只有上帝才知道发生了什么——栈指针、程序指针都可能在跨国（国 == 特权态）旅游。为了确保中断处理能够进行（让操作系统能够接管这样的线程），中断处理必须运行在一个准备好的、安全的栈上。这就是内核栈。不过，内核栈并没有存储在线程信息中。（注：它的使用方法会有些复杂，我们会在后面讲解。） os/src/process/thread.rs /// 线程的信息 pub struct Thread { /// 线程 ID pub id: ThreadID, /// 线程的栈 pub stack: Range, /// 线程执行上下文 /// /// 当且仅当线程被暂停执行时，`context` 为 `Some` pub context: Mutex>, /// 所属的进程 pub process: Arc>, } 进程的表示 在我们实现的简单操作系统中，进程只需要维护页面映射，并且存储一点额外信息： 用户态标识：我们会在后面进行区分内核态线程和用户态线程。 访存空间MemorySet：进程中的线程会共享同一个页表，即可以访问的虚拟内存空间（简称：访存空间）。 os/src/process/process.rs /// 进程的信息 pub struct Process { /// 是否属于用户态 pub is_user: bool, /// 进程中的线程公用页表 / 内存映射 pub memory_set: MemorySet, } var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-4/guide/part-2.html":{"url":"docs/lab-4/guide/part-2.html","title":"线程的创建","keywords":"","body":"线程的创建 接下来，我们的第一个目标就是创建一个线程并且让他运行起来。一个线程要开始运行，需要这些准备工作： 建立页表映射，需要包括以下映射空间： 线程所执行的一段指令 线程执行栈 操作系统的部分内存空间 设置起始执行的地址 初始化各种寄存器，比如 sp 可选：设置一些执行参数（例如 argc, argv等 ） 思考：为什么线程即便与操作系统无关，也需要在内存中映射操作系统的内存空间呢？ Click to show 当发生中断时，需要跳转到 stvec 所指向的中断处理过程。如果操作系统的内存不在页表之中，将无法处理中断。 当然，也不是所有操作系统的代码都需要被映射，但是为了实现简便，我们会为每个进程的页表映射全部操作系统的内存。而由于这些页表都标记为内核权限（即 U 位为 0），也不必担心用户线程可以随意访问。 执行第一个线程 因为启动线程需要修改各种寄存器的值，所以我们又要使用汇编了。不过，这一次我们只需要对 interrupt.asm 稍作修改就可以了。 在 interrupt.asm 中的 __restore 标签现在就能派上用途了。原本这段汇编代码的作用是将之前所保存的 Context 恢复到寄存器中，而现在我们让它使用一个精心设计的 Context，就可以让程序在恢复后直接进入我们的新线程。 首先我们稍作修改，添加一行 mv sp, a0。原本这里是读取之前存好的 Context，现在我们让其从 a0 中读取我们设计好的 Context。这样，我们可以直接在 Rust 代码中调用 __restore(context)。 os/src/interrupt.asm __restore: mv sp, a0 # 加入这一行 # ... 那么我们需要如何设计 Context 呢？ 通用寄存器 sp：应当指向该线程的栈顶 a0-a7：按照函数调用规则，用来传递参数 ra：线程执行完应该跳转到哪里呢？在后续系统调用章节我们会介绍正确的处理方式。现在，我们先将其设为一个不可执行的地址，这样线程一结束就会触发页面异常 sepc 执行 sret 指令后会跳转到这里，所以 sepc 应当存储线程的入口地址（执行的函数地址） sstatus spp 位按照用户态或内核态有所不同 spie 位为 1 [info] sstatus 标志位的具体意义 spp：中断前系统处于内核态（1）还是用户态（0） sie：内核态是否允许中断。对用户态而言，无论 sie 取何值都开启中断 spie：中断前是否开中断（用户态中断时可能 sie 为 0） 硬件处理流程 在中断发生时，系统要切换到内核态。此时，切换前的状态会被保存在 spp 位中（1 表示切换前处于内核态）。同时，切换前是否开中断会被保存在 spie 位中，而 sie 位会被置 0，表示关闭中断。 在中断结束，执行 sret 指令时，会根据 spp 位的值决定 sret 执行后是处于内核态还是用户态。与此同时，spie 位的值会被写入 sie位，而 spie 位置 1。这样，特权状态和中断状态就全部恢复了。 为何如此繁琐？ 特权状态：中断处理流程必须切换到内核态，所以中断时需要用 spp 来保存之前的状态。回忆计算机组成原理的知识，sret 指令必须同时完成跳转并切换状态的工作。 中断状态：中断刚发生时，必须关闭中断，以保证现场保存的过程不会被干扰。同理，现场恢复的过程也必须关中断。因此，需要有以上两个硬件自动执行的操作。由于中断可能嵌套，在保存现场后，根据中断的种类，可能会再开启部分中断的使能。 设计好 Context 之后，我们只需要将它应用到所有的寄存器上（即执行 __restore），就可以切换到第一个线程了。 os/src/process/processor.rs /// 第一次开始运行 /// /// 从 `current_thread` 中取出 [`Context`]，然后直接调用 `interrupt.asm` 中的 `__restore` /// 来从 `Context` 中继续执行该线程。 pub fn run(&mut self) -> ! { // interrupt.asm 中的标签 extern \"C\" { fn __restore(context: usize); } /* 激活线程的页表，取得 Context。具体过程会在后面讲解 */ unsafe { __restore(context); } unreachable!() } 等一下，run() 为什么返回 !！ 我们直接调用的 __restore 并没有 ret 指令，甚至 ra 都会被 Context 中的数值直接覆盖。这意味着，一旦我们执行了 __restore(context)，程序就无法返回到调用它的位置了。注：直接 jump 是一个非常危险的操作。 但是没有关系，我们也不需要这个函数返回。因为开始执行第一个线程，意味着操作系统的初始化已经完成，再回到 rust_main() 也没有意义了。甚至原本我们使用的栈 bootstack，也可以被回收（不过我们现在就丢掉不管吧）。 在启动时不打开中断 现在，我们会在线程开始运行时开启中断，而在操作系统初始化的过程中是不应该有中断的。所以，我们删去之前设置「开启中断」的代码。 os/interrupt/timer.rs /// 初始化时钟中断 /// /// 开启时钟中断使能，并且预约第一次时钟中断 pub fn init() { unsafe { // 开启 STIE，允许时钟中断 sie::set_stimer(); // （删除）开启 SIE（不是 sie 寄存器），允许内核态被中断打断 // sstatus::set_sie(); } // 设置下一次时钟中断 set_next_timeout(); } 小结 为了执行一个线程，我们需要初始化所有寄存器的值。为此，我们选择构建一个 Context 然后跳转至 interrupt.asm 中的 __restore 来执行，用这个 Context 来写入所有寄存器。 思考 __restore 现在会将 a0 寄存器视为一个 *mut Context 来读取，因此我们在执行第一个线程时只需调用 __restore(context)。 那么，如果是程序发生了中断，执行到 __restore 的时候，a0 的值又是谁赋予的呢？ var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-4/guide/part-3.html":{"url":"docs/lab-4/guide/part-3.html","title":"线程的切换","keywords":"","body":"线程的切换 回答一下前一节的思考题：当发生中断时，在 __restore 时，a0 寄存器的值是 handle_interrupt 函数的返回值。也就是说，如果我们令 handle_interrupt 函数返回另一个线程的 *mut Context，就可以在时钟中断后跳转到这个线程来执行。 修改中断处理 在线程切换时（即时钟中断时），handle_interrupt 函数需要将上一个线程的 Context 保存起来，然后将下一个线程的 Context 恢复并返回。 注 1：为什么不直接 in-place 修改 Context 呢？这是因为 handle_interrupt 函数返回的 Context 指针除了存储上下文以外，还提供了内核栈的地址。这个会在后面详细阐述。 注 2：在 Rust 中，引用 &mut 和指针 *mut 只是编译器的理解不同，其本质都是一个存储对象地址的寄存器。这里返回值使用指针而不是引用，是因为其指向的位置十分特殊，其生命周期在这里没有意义。 os/src/interrupt/handler.rs /// 中断的处理入口 #[no_mangle] pub fn handle_interrupt(context: &mut Context, scause: Scause, stval: usize) -> *mut Context { /* ... */ } /// 处理 ebreak 断点 fn breakpoint(context: &mut Context) -> *mut Context { println!(\"Breakpoint at 0x{:x}\", context.sepc); context.sepc += 2; context } /// 处理时钟中断 fn supervisor_timer(context: &mut Context) -> *mut Context { timer::tick(); PROCESSOR.get().tick(context) } 可以看到，当发生断点中断时，直接返回原来的上下文（修改一下 sepc）；而如果是时钟中断的时候，我们通过执行PROCESSOR.get().tick(context)函数得到的返回值作为上下文，那它又是怎么工作的呢？ 线程切换 让我们看一下 Processor::tick 函数是如何实现的。 （调度器 scheduler 会在后面的小节中讲解，我们只需要知道它能够返回下一个等待执行的线程。） os/src/process/processor.rs: impl Processor /// 在一个时钟中断时，替换掉 context pub fn tick(&mut self, context: &mut Context) -> *mut Context { // 向调度器询问下一个线程 if let Some(next_thread) = self.scheduler.get_next() { if next_thread == self.current_thread() { // 没有更换线程，直接返回 Context context } else { // 准备下一个线程 let next_context = next_thread.run(); let current_thread = self.current_thread.replace(next_thread).unwrap(); // 储存当前线程 Context current_thread.park(*context); // 返回下一个线程的 Context next_context } } else { panic!(\"all threads terminated, shutting down\"); } } 上下文 Context 的保存和取出 在线程切换时，我们需要保存前一个线程的 Context，为此我们实现 Thread::park函数。 os/src/process/thread.rs: impl Thread /// 发生时钟中断后暂停线程，保存状态 pub fn park(&self, context: Context) { // 检查目前线程内的 context 应当为 None let mut slot = self.context.lock(); assert!(slot.is_none()); // 将 Context 保存到线程中 slot.replace(context); } 然后，我们需要取出下一个线程的 Context，为此我们实现 Thread::run。不过这次需要注意的是，启动一个线程除了需要 Context，还需要切换页表。这个操作我们也在这个方法中完成。 os/src/process/thread.rs: impl Thread /// 准备执行一个线程 /// /// 激活对应进程的页表，并返回其 Context pub fn run(&self) -> *mut Context { // 激活页表 self.process.read().memory_set.activate(); // 取出 Context let parked_frame = self.context.lock().take().unwrap(); if self.process.read().is_user { // 用户线程则将 Context 放至内核栈顶 KERNEL_STACK.push_context(parked_frame) } else { // 内核线程则将 Context 放至 sp 下 let context = (parked_frame.sp() - size_of::()) as *mut Context; unsafe { *context = parked_frame }; context } } 思考：在 run 函数中，我们在一开始就激活了页表，会不会导致后续流程无法正常执行？ Click to show 不会，因为每一个进程的 MemorySet 都会映射操作系统的空间，否则在遇到中断的时候，将无法执行异常处理。 内核栈？ 现在，线程保存 Context 都是根据 sp 指针，在栈上压入一个 Context 来存储。但是，对于一个用户线程而言，它在用户态运行时用的是位于用户空间的用户栈。而它在用户态运行中如果触发中断，sp 指针指向的是用户空间的某地址，但此时RISC-V CPU会切换到内核态继续执行，就不能再用这个sp指针指向的用户空间地址了。这样，我们需要为sp指针准备好一个专门用于在内核态执行函数的内核栈。所以，为了不让一个线程的崩溃导致操作系统的崩溃，我们需要提前准备好内核栈，当线程发生中断时可用来存储线程的 Context。在下一节我们将具体讲解该如何做。 小结 为了实现线程的切换，我们让 handle_interrupt 返回一个 *mut Context。如果需要切换线程，就将前一个线程的 Context 保存起来换上新的线程的 Context。而如果不需要切换，那么直接返回原本的 Context 即可。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-4/guide/part-4.html":{"url":"docs/lab-4/guide/part-4.html","title":"内核栈","keywords":"","body":"内核栈 为什么 / 怎么做 在实现内核栈之前，让我们先检查一下需求和我们的解决办法。 不是每个线程都需要一个独立的内核栈，因为内核栈只会在中断时使用，而中断结束后就不再使用。在只有一个CPU的情况下，不会有两个线程同时出现中断，所以我们只需要实现一个共用的内核栈就可以了。 每个线程都需要能够在中断时第一时间找到内核栈的地址。这时，所有通用寄存器的值都无法预知，也无法从某个变量来加载地址。为此，我们将内核栈的地址存放到内核态使用的特权寄存器 sscratch 中。这个寄存器只能在内核态访问，这样在中断发生时，就可以安全地找到内核栈了。 因此，我们的做法就是： 预留一段空间作为内核栈 运行线程时，在 sscratch 寄存器中保存内核栈指针 如果线程遇到中断，则从将 Context 压入 sscratch 指向的栈中（Context 的地址为 sscratch - size_of::()），同时用新的栈地址来替换 sp（此时 sp 也会被复制到 a0 作为 handle_interrupt 的参数） 从中断中返回时（__restore 时），a0 应指向被压在内核栈中的 Context。此时出栈 Context 并且将栈顶保存到 sscratch 中 实现 为内核栈预留空间 我们直接使用一个 static mut 来指定一段空间作为栈。 os/src/process/kernel_stack.rs /// 内核栈 #[repr(align(16))] #[repr(C)] pub struct KernelStack([u8; KERNEL_STACK_SIZE]); /// 公用的内核栈 pub static mut KERNEL_STACK: KernelStack = KernelStack([0; STACK_SIZE]); 在我们创建线程时，需要使用的操作就是在内核栈顶压入一个初始状态 Context： os/src/process/kernel_stack.rs impl KernelStack { /// 在栈顶加入 Context 并且返回新的栈顶指针 pub fn push_context(&mut self, context: Context) -> *mut Context { // 栈顶 let stack_top = &self.0 as *const _ as usize + size_of::(); // Context 的位置 let push_address = (stack_top - size_of::()) as *mut Context; unsafe { *push_address = context; } push_address } } 修改 interrupt.asm 在这个汇编代码中，我们需要加入对 sscratch 的判断和使用。 os/src/interrupt.asm __interrupt: # 因为线程当前的栈不一定可用，必须切换到内核栈来保存 Context 并进行中断流程 # 因此，我们使用 sscratch 寄存器保存内核栈地址 # 思考：sscratch 的值最初是在什么地方写入的？ # 交换 sp 和 sscratch（切换到内核栈） csrrw sp, sscratch, sp # 在内核栈开辟 Context 的空间 addi sp, sp, -36*8 # 保存通用寄存器，除了 x0（固定为 0） SAVE x1, 1 # 将本来的栈地址 sp（即 x2）保存 csrr x1, sscratch SAVE x1, 2 SAVE x3, 3 SAVE x4, 4 # ... 以及事后的恢复： os/src/interrupt.asm # 离开中断 # 此时内核栈顶被推入了一个 Context，而 a0 指向它 # 接下来从 Context 中恢复所有寄存器，并将 Context 出栈（用 sscratch 记录内核栈地址） # 最后跳转至恢复的 sepc 的位置 __restore: # 从 a0 中读取 sp # 思考：a0 是在哪里被赋值的？（有两种情况） mv sp, a0 # 恢复 CSR LOAD t0, 32 LOAD t1, 33 csrw sstatus, t0 csrw sepc, t1 # 将内核栈地址写入 sscratch addi t0, sp, 36*8 csrw sscratch, t0 # 恢复通用寄存器 # ... 小结 为了能够鲁棒地处理用户线程产生的异常，我们为线程准备好一个内核栈，发生中断时会切换到这里继续处理。 思考 在栈的切换过程中，会不会导致一些栈空间没有被释放，或者被错误释放的情况？ var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-4/guide/part-5.html":{"url":"docs/lab-4/guide/part-5.html","title":"线程调度","keywords":"","body":"调度器 处理器抽象 我们已经可以创建和保存线程了，现在，我们再抽象出「处理器」来存放和管理线程池。同时，也需要存放和管理目前正在执行的线程（即中断前执行的线程，因为操作系统在工作时是处于中断、异常或系统调用服务之中）。 os/src/process/processor.rs lazy_static! { /// 全局的 [`Processor`] pub static ref PROCESSOR: UnsafeWrapper = Default::default(); } /// 线程调度和管理 #[derive(Default)] pub struct Processor { /// 当前正在执行的线程 current_thread: Option>, /// 线程调度器，记录所有线程 scheduler: SchedulerImpl>, } 注意到这里我们用了一个 UnsafeWrapper，这个东西相当于 Rust 提供的 UnsafeCell，或者 C 语言的指针：任何线程都可以随时从中获取一个 &'static mut 引用。由于在我们的设计中，只有时钟中断（以及异常或未来的系统调用）时可以使用 PROCESSOR，而在此过程中，操作系统是关闭时钟中断的。因此，这里使用 UnsafeCell 是安全的。 调度器 调度器的算法有许多种，我们将它提取出一个 trait 作为接口 os/src/algorithm/src/scheduler/mod.rs /// 线程调度器 /// /// 这里 `ThreadType` 就是 `Arc` pub trait Scheduler: Default { /// 向线程池中添加一个线程 fn add_thread(&mut self, thread: ThreadType, priority: T); /// 获取下一个时间段应当执行的线程 fn get_next(&mut self) -> Option; /// 移除一个线程 fn remove_thread(&mut self, thread: ThreadType); /// 设置线程的优先级 fn set_priority(&mut self, thread: ThreadType, priority: T); } 具体的算法就不在此展开了，我们可以参照目录 os/src/algorithm/src/scheduler 下的一些样例。 运行！ 最后，让我们补充 Processor::run 的实现，让我们运行起第一个线程！ os/src/process/processor.rs: impl Processor /// 第一次开始运行 pub fn run(&mut self) -> ! { // interrupt.asm 中的标签 extern \"C\" { fn __restore(context: usize); } // 从 current_thread 中取出 Context let context = self.current_thread().run(); // 从此将没有回头 unsafe { __restore(context as usize); } unreachable!() } 修改 main.rs，我们就可以跑起来多线程了。 os/src/main.rs /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main() -> ! { memory::init(); interrupt::init(); // 新建一个带有内核映射的进程。需要执行的代码就在内核中 let process = Process::new_kernel().unwrap(); for message in 0..8 { let thread = Thread::new( process.clone(), // 使用同一个进程 sample_process as usize, // 入口函数 Some(&[message]), // 参数 ).unwrap(); PROCESSOR.get().add_thread(thread); } // 把多余的 process 引用丢弃掉 drop(process); PROCESSOR.get().run(); } fn sample_process(message: usize) { for i in 0..1000000 { if i % 200000 == 0 { println!(\"thread {}\", message); } } } 运行一下，我们会得到类似的输出： 运行输出 thread 7 thread 6 thread 5 ... thread 7 ... thread 2 thread 1 thread 0 ... var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-4/guide/summary.html":{"url":"docs/lab-4/guide/summary.html","title":"小结","keywords":"","body":"小结 本章我们的工作有： 理清线程和进程的概念 通过设置 Context，可以构造一个线程的初始状态 通过 __restore 标签，直接进入第一个线程之中 用 Context 来保存进程的状态，从而实现在时钟中断时切换线程 实现内核栈，提供安全的中断处理空间 实现调度器，完成线程的调度 同时，可以发现我们这一章的内容集中在内核线程上面，对用户进程还没有过多的提及。而为了让用户进程可以在我们的系统上运行起来，一个优美的做法将会是隔开用户程序和内核。需要注意到现在的内核还直接放在了内存上，在下一个章节，我们暂时跳过用户进程，实现可以放置用户数据的文件系统。 思考 可以看到我们的设计中用了大量的锁结构，很多都是为了让 Rust 知道我们是安全的，而且大部分情况下我们仅仅会在中断发生的时候来使用这些逻辑，这意味着，只要内核线程里面不用，就不会发生死锁，但是真的是这样吗？即使我们不在内核中使用各种 Processor 和 Thread 等等的逻辑，仅仅完成一些简单的运算，真的没有死锁吗？ Click to show 会有死锁，比如我们在内核线程中构造一个 Vec，然后在里面 push 几个元素，这个时候就可能产生死锁。 需要注意到，我们的动态分配器是一个 LockedHeap，是外面加了锁的一个分配器，如果在线程里面 push 的过程中需要动态分配，然后正好在上完锁而且没有释放锁的时候产生了中断，而中断中我们的 Scheduler 也用到了 Vec，这个时候会再去锁住，但是又拿不到，同时需要注意的是在处理中断本身时，我们的时钟中断是关掉的，这意味着我们的锁会一直去申请，就形成了类似死锁的死循环。 解决这个问题需要把申请到锁之后加上关闭中断，通过这种抢占式的方法彻底执行完分配逻辑之后再关闭锁同时打开中断。这个问题是一个设计上的取舍，如果我们不支持内核抢占，就需要很多精妙的设计来绕开这个问题。在这里，我们先不会理会这个问题。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-5/guide/intro.html":{"url":"docs/lab-5/guide/intro.html","title":"摘要","keywords":"","body":"实验指导五 实验概要 这一章的实验指导中，你将会学到： 设备树的概念和读取 virtio 总线协议 块设备驱动的实现 将块设备托管给文件系统 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-5/guide/part-1.html":{"url":"docs/lab-5/guide/part-1.html","title":"设备树","keywords":"","body":"设备树 从哪里读取设备信息 既然我们要实现把数据放在某个存储设备上并让操作系统来读取，首先操作系统就要有一个读取全部已接入设备信息的能力，而设备信息放在哪里又是谁帮我们来做的呢？这个问题其实在物理内存探测中就提到过，在 RISC-V 中，这个一般是由 Bootloader，即 OpenSBI 固件完成的。它来完成对于包括物理内存在内的各外设的扫描，将扫描结果以设备树二进制对象（DTB，Device Tree Blob）的格式保存在物理内存中的某个地方。而这个放置的物理地址将放在 a1 寄存器中，而将会把 HART ID （HART，Hardware Thread，硬件线程，可以理解为执行的 CPU 核）放在 a0 寄存器上。 在我们之前的函数中并没有使用过这两个参数，如果要使用，我们不需要修改任何入口汇编的代码，只需要给 rust_main 函数增加两个参数即可： os/src/main.rs /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main(_hart_id: usize, dtb_pa: PhysicalAddress) -> ! { memory::init(); interrupt::init(); drivers::init(dtb_pa); ... } 打印输出一下，dtb_pa 变量约在 0x82200000 附近，而内核结束的地址约为 0x80b17000，也就是在我们内核的后面放着，这意味着当我们内核代码超过 32MB 的时候就会出现问题，在更好的实现中，其实 OpenSBI 固件启动的应该是第二级小巧的 Bootloader，而我们现在全部内核内容都在内存中且也没 32MB 那么大，我们暂时不理会这个问题。 设备树 上面提到 OpenSBI 固件会把设备信息以设备树的格式放在某个地址上，哪设备树格式究竟是怎样的呢？在各种操作系统中，我们打开设备管理器（Windows）和系统报告（macOS）等内置的系统软件就可以看到我们使用的电脑的设备树，一个典型的设备树如下图所示： 每个设备在物理上连接到了父设备上最后再通过总线等连接起来构成一整个设备树，在每个节点上都描述了对应设备的信息，如支持的协议是什么类型等等。而操作系统就是通过这些节点上的信息来实现对设备的识别的。 [info] 设备节点属性 具体而言，一个设备节点上会有几个标准属性，这里简要介绍我们需要用到的几个： compatible：该属性指的是该设备的编程模型，一般格式为 \"manufacturer,model\"，分别指一个出厂标签和具体模型。如 \"virtio,mmio\" 指的是这个设备通过 virtio 协议、MMIO（内存映射 I/O）方式来驱动 model：指的是设备生产商给设备的型号 reg：当一些很长的信息或者数据无法用其他标准属性来定义时，可以用 reg 段来自定义存储一些信息 设备树是一个比较复杂的标准，更多细节可以参考 Device Tree Reference。 解析设备树 对于上面的属性，我们不需要自己来实现这件事情，可以直接调用 rCore 中 device_tree 库，然后遍历树上节点即可： os/src/drivers/device_tree.rs /// 递归遍历设备树 fn walk(node: &Node) { // 检查设备的协议支持并初始化 if let Ok(compatible) = node.prop_str(\"compatible\") { if compatible == \"virtio,mmio\" { virtio_probe(node); } } // 遍历子树 for child in node.children.iter() { walk(child); } } /// 整个设备树的 Headers（用于验证和读取） struct DtbHeader { magic: u32, size: u32, } /// 遍历设备树并初始化设备 pub fn init(dtb_va: VirtualAddress) { let header = unsafe { &*(dtb_va.0 as *const DtbHeader) }; // from_be 是大小端序的转换（from big endian） let magic = u32::from_be(header.magic); if magic == DEVICE_TREE_MAGIC { let size = u32::from_be(header.size); // 拷贝数据，加载并遍历 let data = unsafe { slice::from_raw_parts(dtb_va.0 as *const u8, size as usize) }; if let Ok(dt) = DeviceTree::load(data) { walk(&dt.root); } } } 注：在开始的时候，有一步来验证 Magic Number，这一步是一个保证系统可靠性的要求，是为了验证这段内存到底是不是设备树。在遍历过程中，一旦发现了一个支持 \"virtio,mmio\" 的设备（其实就是 QEMU 模拟的存储设备），就进入下一步加载驱动的逻辑。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-5/guide/part-2.html":{"url":"docs/lab-5/guide/part-2.html","title":"virtio","keywords":"","body":"virtio 挂载到 QEMU 为了让 QEMU 挂载上我们虚拟的存储设备，我们这里选了 QEMU 支持的 virtio 协议，需要在 QEMU 运行的时候加入选项： os/Makefile # 运行 QEMU qemu: build @qemu-system-riscv64 \\ -machine virt \\ -nographic \\ -bios default \\ -device loader,file=$(BIN_FILE),addr=0x80200000 \\ -drive file=$(TEST_IMG),format=raw,id=sfs \\ # 模拟存储设备 -device virtio-blk-device,drive=sfs # 以 virtio Block Device 的形式挂载到 virtio 总线上 其中的 TEST_IMG 是特定文件系统格式的磁盘镜像，我们在本小节还不会提及到这个概念，这里可以直接用目录下的测试镜像。 什么是 virtio virtio 起源于 virtio: Towards a De-Facto Standard For Virtual I/O Devices 这篇论文，主要针对于半虚拟化技术中对通用设备的抽象。 [info] 完全虚拟化和半虚拟化 在完全虚拟化中，被虚拟的操作系统运行在位于物理机器上的 Hypervisor 之上。被虚拟的操作系统并不知道它已被虚拟化，并且不需要任何更改就可以在该配置下工作。相反，在半虚拟化中，被虚拟的操作系统不仅知道它运行在 Hypervisor 之上，还包含让被虚拟的操作系统更高效地过渡到 Hypervisor 的代码。 在完全虚拟化模式中，Hypervisor 必须模拟设备硬件，它是在会话的最低级别进行模拟的（例如，网络驱动程序）。尽管在该抽象中模拟很干净，但它同时也是最低效、最复杂的。在半虚拟化模式中，被虚拟的操作系统和 Hypervisor 能够共同合作，让模拟更加高效。半虚拟化方法的缺点是操作系统知道它被虚拟化，并且需要修改才能工作。 具体来说，virtio 的架构如图所示： 以 virtio 为中心的总线下又挂载了 virtio-blk（块设备）总线、virtio-net（网络设备）总线、virtio-pci（PCI 设备）总线等，本身就构成一个设备树。 virtio 节点探测 在上一节中，我们实现了对 \"virtio,mmio\" 的节点的判断，下面我们进一步来区分上面提到的那些 virtio 设备： os/src/drivers/bus/virtio_mmio.rs /// 从设备树的某个节点探测 virtio 协议具体类型 pub fn virtio_probe(node: &Node) { // reg 属性中包含了描述设备的 Header 的位置 let reg = match node.prop_raw(\"reg\") { Some(reg) => reg, _ => return, }; let pa = PhysicalAddress(reg.as_slice().read_be_u64(0).unwrap() as usize); let va = VirtualAddress::from(pa); let header = unsafe { &mut *(va.0 as *mut VirtIOHeader) }; // 目前只支持某个特定版本的 virtio 协议 if !header.verify() { return; } // 判断设备类型 match header.device_type() { DeviceType::Block => virtio_blk::add_driver(header), device => println!(\"unrecognized virtio device: {:?}\", device), } } 从设备树节点的 reg 信息中可以读出设备更详细信息的放置位置（如：在 0x10000000 - 0x10010000 ），这段区间虽然算是内存区间，但是还记得的吗？我们的物理内存只分布在 0x80000000 到 0x88000000 的空间中，那这段空间哪里来的呢？这就是所谓的内存映射读写 MMIO（Memory Mapped I/O），也就是总线把对设备操作信息传递也映射成了内存的一部分，CPU 操作设备和访问内存的形式没有任何的区别，但读写效果是不同的。大家可以回忆一下计算机组成原理中对串口的访问，这里是一个道理。 所以，为了访问这段地址，我们也需要把它加到页表里面，分别对应在 os/src/asm/entry.asm 中的 boot_page_table 以及 os/src/memory/mapping/memory_set.rs 的新建内核线程中加入了这段地址，使得我们的内核线程可以访问他们。 virtio_drivers 库 我们在这里不会自己来实现驱动的每一个细节，同样的，我们使用 rCore 中的 virtio_drivers 库，这个库会帮我们通过 MMIO 的方式对设备进行交互，同时我们也需要给这个库提供一些诸如申请物理内存、物理地址虚拟转换等接口。 os/src/drivers/bus/virtio_mmio.rs lazy_static! { /// 用于放置给设备 DMA 所用的物理页（[`FrameTracker`]） pub static ref TRACKERS: RwLock> = RwLock::new(BTreeMap::new()); } /// 为 DMA 操作申请连续 pages 个物理页（为 [`virtio_drivers`] 库提供） /// /// 为什么要求连续的物理内存？设备的 DMA 操作只涉及到内存和对应设备 /// 这个过程不会涉及到 CPU 的 MMU 机制，我们只能给设备传递物理地址 /// 而陷于我们之前每次只能分配一个物理页的设计，这里我们假设我们连续分配的地址是连续的 #[no_mangle] extern \"C\" fn virtio_dma_alloc(pages: usize) -> PhysicalAddress { let mut pa: PhysicalAddress = Default::default(); let mut last: PhysicalAddress = Default::default(); for i in 0..pages { let tracker: FrameTracker = FRAME_ALLOCATOR.lock().alloc().unwrap(); if i == 0 { pa = tracker.address(); } else { assert_eq!(last + PAGE_SIZE, tracker.address()); } last = tracker.address(); TRACKERS.write().insert(last, tracker); } return pa; } /// 为 DMA 操作释放对应的之前申请的连续的物理页（为 [`virtio_drivers`] 库提供） #[no_mangle] extern \"C\" fn virtio_dma_dealloc(pa: PhysicalAddress, pages: usize) -> i32 { for i in 0..pages { TRACKERS.write().remove(&(pa + i * PAGE_SIZE)); } 0 } /// 将物理地址转为虚拟地址（为 [`virtio_drivers`] 库提供） /// /// 需要注意，我们在 0xffffffff80200000 到 0xffffffff88000000 是都有对应的物理地址映射的 /// 因为在内核重映射的时候，我们已经把全部的段放进去了 /// 所以物理地址直接加上 Offset 得到的虚拟地址是可以通过任何内核进程的页表来访问的 #[no_mangle] extern \"C\" fn virtio_phys_to_virt(pa: PhysicalAddress) -> VirtualAddress { VirtualAddress::from(pa) } /// 将虚拟地址转为物理地址（为 [`virtio_drivers`] 库提供） /// /// 需要注意，实现这个函数的目的是告诉 DMA 具体的请求，请求在实现中会放在栈上面 /// 而在我们的实现中，栈是以 Framed 的形式分配的，并不是高地址的线性映射 Linear /// 为了得到正确的物理地址并告诉 DMA 设备，我们只能查页表 #[no_mangle] extern \"C\" fn virtio_virt_to_phys(va: VirtualAddress) -> PhysicalAddress { Mapping::lookup(va).unwrap() } 至于为什么要实现这些操作，是因为本身设备是通过直接内存访问DMA（Direct Memory Access）技术来实现数据传输的，CPU 只需要给出要传输哪些内容，放在哪段物理内存上面，把请求告诉设备，设备后面的操作就会利用 DMA 而不经过 CPU 直接传输，在传输结束之后，会通过中断请求 IRQ（Interrupt ReQuest）技术沿着设备树把\"我做完了\"这个信息告诉 CPU，CPU 会作为一个中断进一步处理。而为了实现 DMA，我们需要一些请求和内存空间，比如让磁盘把数据传到某个内存段，我们需要告诉设备内存的物理地址（之所以不是虚拟地址是因为 DMA 不会经过 CPU 的 MMU 技术），而且这个物理地址最好是连续的。同时，我们在栈上申请一个请求的结构，这个结构的物理地址也要告诉设备，所以也需要一些虚实地址转换的接口。 现在，我们的 FRAME_ALLOCATOR 还只能分配一个帧出来，我们连续调用，暂时先假设他是连续的。同时注意到，为了实现虚实物理转换，我们需要查找页表，很不幸的是 RISC-V 并没有给我提供一个很方便的根据当前页表找到物理地址的指令，所以这里我们在 os/src/memory/mapping/mapping.rs 中实现了一个类似的功能。 思考 为什么物理地址到虚拟地址转换直接线性映射，而虚拟地址到物理地址却要查表？ Click to show 我们拿到地址的究极目的是访问地址上的内容，需要注意到在 0x80000000 到 0x88000000 的区间的物理页有可能对应着两个虚拟页，我们在启动或是新建内核线程的时候都包含诸如 0xffffffff80000000 到 0x80000000 这样的线性映射，这意味着，在内核线程里面，只要一个物理地址加上偏移得到的虚拟地址肯定是可以访问对应的物理地址的。所以，把物理地址转为虚拟地址加个偏移既可。 也需要注意到，内核线程虽然代码和数据都是线性映射的，但是内核栈是以 Frame 为单位分配的（除了 boot 线程是直接放在 .bss 中），而以 Frame 为单位分配意味着，虚拟地址可能从 0 开始，这个时候要转为物理地址，显然不是减去偏移量的线性映射，而必须查当前的表。 这个时候，你可能问了：为什么 RISC-V 处理器可以通过虚拟地址来访问，但是我还要手写查表来做这件事呢？这是因为 RISC-V 还真没有直接用 MMU 得到地址的指令，我们只能手写。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-5/guide/part-3.html":{"url":"docs/lab-5/guide/part-3.html","title":"驱动和块设备驱动","keywords":"","body":"驱动和块设备驱动 什么是块设备 注意到我们在介绍 virtio 时提到了 virtio-blk 设备，这种设备提供了以整块为粒度的读和写操作，一般对应到真实的物理设备是那种硬盘。而之所以是以块为单位是为了加快读写的速度，毕竟硬盘等设备还需要寻道等等操作，一次性读取很大的一块将会节约很多时间。 抽象驱动 在写块设备驱动之前，我们先抽象驱动的概念，也方便后面网络设备等的介入。 os/src/drivers/driver.rs /// 驱动类型 /// /// 目前只有块设备，可能还有网络、GPU 设备等 #[derive(Debug, Eq, PartialEq)] pub enum DeviceType { Block, } /// 驱动的接口 pub trait Driver: Send + Sync { /// 设备类型 fn device_type(&self) -> DeviceType; /// 读取某个块到 buf 中（块设备接口） fn read_block(&self, _block_id: usize, _buf: &mut [u8]) -> bool { unimplemented!(\"not a block driver\") } /// 将 buf 中的数据写入块中（块设备接口） fn write_block(&self, _block_id: usize, _buf: &[u8]) -> bool { unimplemented!(\"not a block driver\") } } lazy_static! { /// 所有驱动 pub static ref DRIVERS: RwLock>> = RwLock::new(Vec::new()); } 这里暂时只有块设备这个种类，不过这样写还是为了方便未来的扩展。 抽象块设备 有了驱动的概念，我们进一步抽象块设备： /// 块设备抽象（驱动的引用） pub struct BlockDevice(pub Arc); /// 为 [`BlockDevice`] 实现 [`rcore-fs`] 中 [`BlockDevice`] trait /// /// 使得文件系统可以通过调用块设备的该接口来读写 impl dev::BlockDevice for BlockDevice { /// 每个块的大小（取 2 的对数） /// /// 这里取 512B 是因为 virtio 驱动对设备的操作粒度为 512B const BLOCK_SIZE_LOG2: u8 = 9; /// 读取某个块到 buf 中 fn read_at(&self, block_id: usize, buf: &mut [u8]) -> dev::Result { match self.0.read_block(block_id, buf) { true => Ok(()), false => Err(dev::DevError), } } /// 将 buf 中的数据写入块中 fn write_at(&self, block_id: usize, buf: &[u8]) -> dev::Result { match self.0.write_block(block_id, buf) { true => Ok(()), false => Err(dev::DevError), } } /// 执行和设备的同步 /// /// 因为我们这里全部为阻塞 I/O 所以不存在同步的问题 fn sync(&self) -> dev::Result { Ok(()) } } 这里所谓的 BlockDevice 其实就是一个 Driver 的引用。而且利用 rcore-fs 中提供的 BlockDevice trait 实现了为文件系统的接口，实际上是对上传文件系统的连接。 virtio-blk 块设备驱动 最后，我们来实现 virtio-blk 的驱动（主要通过调用现成的库完成）： /// virtio 协议的块设备驱动 struct VirtIOBlkDriver(Mutex>); /// 为 [`VirtIOBlkDriver`] 实现 [`Driver`] trait /// /// 调用了 [`virtio_drivers`] 库，其中规定的块大小为 512B impl Driver for VirtIOBlkDriver { /// 设备类型 fn device_type(&self) -> DeviceType { DeviceType::Block } /// 读取某个块到 buf 中 fn read_block(&self, block_id: usize, buf: &mut [u8]) -> bool { self.0.lock().read_block(block_id, buf).is_ok() } /// 将 buf 中的数据写入块中 fn write_block(&self, block_id: usize, buf: &[u8]) -> bool { self.0.lock().write_block(block_id, buf).is_ok() } } /// 将从设备树中读取出的设备信息放到 [`static@DRIVERS`] 中 pub fn add_driver(header: &'static mut VirtIOHeader) { let virtio_blk = VirtIOBlk::new(header).expect(\"failed to init blk driver\"); let driver = Arc::new(VirtIOBlkDriver(Mutex::new(virtio_blk))); DRIVERS.write().push(driver.clone()); } 需要注意的是，现在的逻辑怎么看都不像是之前提到的异步 DMA + IRQ 中断的高级I/O操作技术，而更像是阻塞的读取。实际上的确是阻塞的读取，目前 virtio-drivers 库中的代码虽然调用了 DMA，但是返回时还是阻塞的逻辑，我们这里为了简化也没有设计 IRQ 的响应机制。 小结 至此，我们完成了全部的驱动逻辑，我们总结一下目前的设计模式如下所示： 其中 Driver 作为一个核心 trait 为上提供实现，上层也就是 Driver 的使用侧（设备的抽象），而下层则是 Driver 的实现侧（设备的实现）。而下一个小节，我们将利用这些驱动来实现文件系统。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-5/guide/part-4.html":{"url":"docs/lab-5/guide/part-4.html","title":"文件系统","keywords":"","body":"文件系统 之前我们在加载 QEMU 的时候引入了一个磁盘镜像文件，这个文件的打包是由 rcore-fs-fuse 工具 来完成的，它会根据不同的格式把目录的文件封装成到一个文件系统中，并把文件系统封装为一个磁盘镜像文件。然后我们把这个镜像文件像设备一样挂载在 QEMU 上，QEMU就把它模拟为一个块设备了。接下来我们需要让操作系统理解块设备里面的文件系统。 Simple File System 因为文件系统本身比较庞大，我们这里还是用了 rCore 中的文件系统模块 rcore-fs，其中实现了很多格式的文件系统，我们这里选择最简单的 Simple File System（这也是为什么 QEMU 中的设备 id 为 sfs），关于文件系统的细节，这里将不展开描述，可以参考前人的分析。 不过，为了使用这个模块，一个自然的想法是存取根目录的 INode（一个 INode 是对一个文件的位置抽象，目录也是文件的一种），后面对于文件系统的操作都可以通过根目录来实现。 实现 这里我们用到了我们的老朋友 lazy_static 宏，将会在我们第一次使用 ROOT_INODE 时进行初始化，而初始化的方式是找到全部设备驱动中的第一个存储设备作为根目录。 os/src/fs/mod.rs lazy_static! { /// 根文件系统的根目录的 INode pub static ref ROOT_INODE: Arc = { // 选择第一个块设备 for driver in DRIVERS.read().iter() { if driver.device_type() == DeviceType::Block { let device = BlockDevice(driver.clone()); // 动态分配一段内存空间作为设备 Cache let device_with_cache = Arc::new(BlockCache::new(device, BLOCK_CACHE_CAPACITY)); return SimpleFileSystem::open(device_with_cache) .expect(\"failed to open SFS\") .root_inode(); } } panic!(\"failed to load fs\") }; } 同时，还可以注意到我们也加入了一个 BlockCache，该模块也是 rcore-fs 提供的，提供了一个存储设备在内存 Cache 的抽象，通过调用 BlockCache::new(device, BLOCK_CACHE_CAPACITY) 就可以把 device 自动变为一个有 Cache 的设备。最后我们用 SimpleFileSystem::open 打开并返回根节点即可。 测试 终于到了激动人心的测试环节了！我们首先在触发一下 ROOT_INODE 的初始化，然后尝试输出一下根目录的内容： os/src/fs/mod.rs /// 打印某个目录的全部文件 pub fn ls(path: &str) { let mut id = 0; let dir = ROOT_INODE.lookup(path).unwrap(); print!(\"files in {}: \\n \", path); while let Ok(name) = dir.get_entry(id) { id += 1; print!(\"{} \", name); } print!(\"\\n\"); } /// 触发 [`static@ROOT_INODE`] 的初始化并打印根目录内容 pub fn init() { ls(\"/\"); println!(\"mod fs initialized\"); } 最后在主函数中测试初始化，然后测试在另一个内核线程中创建个文件夹，而之所以在另一个线程中做是为了验证我们之前写驱动涉及到的页表的那些操作： os/src/fs/mod.rs /// Rust 的入口函数 /// /// 在 `_start` 为我们进行了一系列准备之后，这是第一个被调用的 Rust 函数 #[no_mangle] pub extern \"C\" fn rust_main(_hart_id: usize, dtb_pa: PhysicalAddress) -> ! { memory::init(); interrupt::init(); drivers::init(dtb_pa); fs::init(); let process = Process::new_kernel().unwrap(); PROCESSOR .get() .add_thread(Thread::new(process.clone(), simple as usize, Some(&[0])).unwrap()); // 把多余的 process 引用丢弃掉 drop(process); PROCESSOR.get().run() } /// 测试任何内核线程都可以操作文件系统和驱动 fn simple(id: usize) { println!(\"hello from thread id {}\", id); // 新建一个目录 fs::ROOT_INODE .create(\"tmp\", rcore_fs::vfs::FileType::Dir, 0o666) .expect(\"failed to mkdir /tmp\"); // 输出根文件目录内容 fs::ls(\"/\"); loop {} } make run 一下，你会得到类似的输出： 运行输出 mod memory initialized mod interrupt initialized mod driver initialized files in /: . .. temp rust mod fs initialized hello from thread id 0 files in /: . .. temp rust tmp 100 tick 200 tick ... 成功了！我们可以看到系统正确的读出了文件，而且也正确地创建了文件，这为后面用户进程数据的放置提供了很好的保障。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-5/guide/summary.html":{"url":"docs/lab-5/guide/summary.html","title":"小结","keywords":"","body":"小结 本章我们的工作有： 在 QEMU 上挂载了存储设备 通过读取设备树找到了挂载的设备 实现了 virtio 驱动，把物理设备抽象为了驱动 进一步把驱动抽象给上层文件系统使用 调用 rcore-fs 的文件系统实现对文件的管理 现在，我们再也不会担心用户数据没有地方放置了，在下一个章节中，我们将实现用户进程，并让内核把用户进程加载和运行，实现和用户进程的交互。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-6/guide/intro.html":{"url":"docs/lab-6/guide/intro.html","title":"摘要","keywords":"","body":"实验指导六 实验概要 这一章的实验指导中，你将会学到： 单独生成 ELF 格式的用户程序，并打包进文件系统中 创建并运行用户进程 使用系统调用为用户程序提供服务 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-6/guide/part-1.html":{"url":"docs/lab-6/guide/part-1.html","title":"构建用户程序框架","keywords":"","body":"构建用户程序框架 接下来我们要做的工作，和实验准备中为操作系统「去除依赖」的工作十分类似：我们需要为用户程序提供一个类似的没有Rust std标准运行时依赖的极简运行时环境。这里我们会快速梳理一遍我们为用户程序进行的流程。 建立 crate 我们在与 os 的旁边建立一个 user crate。此时，我们移除默认的 main.rs，而是在 src 目录下建立 lib 和 bin子目录， 在lib中存放的是极简运行时环境，在 bin中存放的源文件会被编译成多个单独的执行文件。 运行命令 cargo new --bin user 目录结构 rCore-Tutorial - os - user - src - bin - hello_world.rs - lib.rs - Cargo.toml 基础框架搭建 和操作系统一样，我们需要为用户程序移除 std 依赖，并且补充一些必要的功能。 lib.rs #![no_std] 移除标准库 #![feature(...)] 开启一些不稳定的功能 #[global_allocator] 使用库来实现动态内存分配 #[panic_handler] panic 时终止 其他文件 .cargo/config 设置编译目标为 RISC-V 64 console.rs 实现 print! println! 宏 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-6/guide/part-2.html":{"url":"docs/lab-6/guide/part-2.html","title":"打包为磁盘镜像","keywords":"","body":"打包为磁盘镜像 在上一章我们已经实现了文件系统，并且可以让操作系统加载磁盘镜像。现在，我们只需要利用工具将编译后的用户程序打包为镜像，就可以使用了。 工具安装 通过 cargo 来安装 rcore-fs-fuse 工具： 运行命令 cargo install rcore-fs-fuse --git https://github.com/rcore-os/rcore-fs 打包 这个工具可以将一个目录打包成 SimpleFileSystem 格式的磁盘镜像。为此，我们需要将编译得到的 ELF 文件单独放在一个导出目录中，即 user/build/disk。 user/Makefile build: dependency # 编译 @cargo build @echo Targets: $(patsubst $(SRC_DIR)/%.rs, %, $(SRC_FILES)) # 移除原有的所有文件 @rm -rf $(OUT_DIR) @mkdir -p $(OUT_DIR) # 复制编译生成的 ELF 至目标目录 @cp $(BIN_FILES) $(OUT_DIR) # 使用 rcore-fs-fuse 工具进行打包 @rcore-fs-fuse --fs sfs $(IMG_FILE) $(OUT_DIR) zip # 将镜像文件的格式转换为 QEMU 使用的高级格式 @qemu-img convert -f raw $(IMG_FILE) -O qcow2 $(QCOW_FILE) # 提升镜像文件的容量（并非实际大小），来允许更多数据写入 @qemu-img resize $(QCOW_FILE) +1G 在 os/Makefile 中指定我们新生成的 QCOW_FILE 为加载镜像，就可以在操作系统中看到打包好的目录了。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-6/guide/part-3.html":{"url":"docs/lab-6/guide/part-3.html","title":"解析 ELF 文件并创建线程","keywords":"","body":"解析 ELF 文件并创建线程 在之前实现内核线程时，我们只需要为线程指定一个起始位置就够了，因为所有的代码都在操作系统之中。但是现在，我们需要从 ELF 文件中加载用户程序的代码和数据信息，并且映射到内存中。 当然，我们不需要自己实现 ELF 文件解析器，因为有 xmas-elf 这个 crate 替我们实现了 ELF 的解析。 xmas-elf 解析器 tips：如果 IDE 无法对其中的类型进行推断，可以在 rustdoc 中找到该 crate 进行查阅。 读取文件内容 xmas-elf 需要将 ELF 文件首先读取到内存中。在上一章文件系统的基础上，我们很容易为 INode 添加一个将整个文件作为 [u8] 读取出来的方法： os/src/fs/inode_ext.rs fn readall(&self) -> Result> { // 从文件头读取长度 let size = self.metadata()?.size; // 构建 Vec 并读取 let mut buffer = Vec::with_capacity(size); unsafe { buffer.set_len(size) }; self.read_at(0, buffer.as_mut_slice())?; Ok(buffer) } 解析各个字段 对于 ELF 中的不同字段，其存放的地址通常是不连续的，同时其权限也会有所不同。我们利用 xmas-elf 库中的接口，便可以从读出的 ELF 文件中对应建立 MemorySet。 注意到，用户程序也会首先映射所有内核态的空间，否则将无法进行中断处理。 os/src/memory/mapping/memory_set.rs /// 通过 elf 文件创建内存映射（不包括栈） pub fn from_elf(file: &ElfFile, is_user: bool) -> MemoryResult { // 建立带有内核映射的 MemorySet let mut memory_set = MemorySet::new_kernel()?; // 遍历 elf 文件的所有部分 for program_header in file.program_iter() { if program_header.get_type() != Ok(Type::Load) { continue; } // 从每个字段读取「起始地址」「大小」和「数据」 let start = VirtualAddress(program_header.virtual_addr() as usize); let size = program_header.mem_size() as usize; let data: &[u8] = if let SegmentData::Undefined(data) = program_header.get_data(file).unwrap() { data } else { return Err(\"unsupported elf format\"); }; // 将每一部分作为 Segment 进行映射 let segment = Segment { map_type: MapType::Framed, range: Range::from(start..(start + size)), flags: Flags::user(is_user) | Flags::readable(program_header.flags().is_read()) | Flags::writable(program_header.flags().is_write()) | Flags::executable(program_header.flags().is_execute()), }; // 建立映射并复制数据 memory_set.add_segment(segment, Some(data))?; } Ok(memory_set) } 加载数据到内存中 思考：我们在为用户程序建立映射时，虚拟地址是 ELF 文件中写明的，那物理地址是程序在磁盘中存储的地址吗？这样做有什么问题吗？ Click to show 我们在模拟器上运行可能不觉得，但是如果直接映射磁盘空间，使用时会带来巨大的延迟，所以需要在程序准备运行时，将其磁盘中的数据复制到内存中。如果程序较大，操作系统可能只会复制少量数据，而更多的则在需要时再加载。当然，我们实现的简单操作系统就一次性全都加载到内存中了。 而且，就算是想要直接映射磁盘空间，也不一定可行。这是因为虚实地址转换时，页内偏移是不变的。这是就无法保证在 ELF 中指定的地址和其在磁盘中的地址满足这样的关系。 我们将修改 Mapping::map 函数，为其增加一个参数表示用于初始化的数据。在实现时，有一些重要的细节需要考虑。 因为用户程序的内存分配是动态的，其分配到的物理页面不一定连续，所以必须单独考虑每一个页面 每一个字段的长度不一定是页大小的倍数，所以需要考虑不足一个页时的复制情况 程序有一个 bss 段，它在 ELF 中不保存数据，而其在加载到内存是需要零初始化 对于一个页面，有其物理地址、虚拟地址和待加载数据的地址。此时，是不是直接从待加载数据的地址拷贝到页面的虚拟地址，如同 memcpy 一样就可以呢？ Click to show 在目前的框架中，只有当线程将要运行时，才会加载其页表。因此，除非我们额外的在每映射一个页面之后，就更新一次页表并且刷新 TLB，否则此时的虚拟地址是无法访问的。 但是，我们通过分配器得到了页面的物理地址，而这个物理地址实际上已经在内核的线性映射当中了。所以，这里实际上用的是物理地址来写入数据。 具体的实现，可以查看 os/src/memory/mapping/mapping.rs 中的 Mapping::map 函数。 运行 Hello World？ 现在，我们就可以在操作系统中运行磁盘镜像中的用户程序了，代码示例如下： os/src/main.rs // 从文件系统中找到程序 let app = fs::ROOT_INODE.find(\"hello_world\").unwrap(); // 读取数据 let data = app.readall().unwrap(); // 解析 ELF 文件 let elf = ElfFile::new(data.as_slice()).unwrap(); // 利用 ELF 文件创建线程，映射空间并加载数据 let process = Process::from_elf(&elf, true).unwrap(); // 再从 ELF 中读出程序入口地址 let thread = Thread::new(process, elf.header.pt2.entry_point() as usize, None).unwrap(); // 添加线程 PROCESSOR.get().add_thread(thread); 可惜的是，我们不能像内核线程一样在用户程序中直接使用 print。前者是基于 OpenSBI 的机器态SBI调用，而为了让用户程序能够打印字符，我们还需要在操作系统中实现系统调用来给用户进程提供服务。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-6/guide/part-4.html":{"url":"docs/lab-6/guide/part-4.html","title":"实现系统调用","keywords":"","body":"实现系统调用 目前，我们实现 sys_read sys_write 和 sys_exit 三个简单的系统调用。通过学习它们的实现，更多的系统调用也并没有多难。 用户程序中调用系统调用 在用户程序中实现系统调用比较容易，就像我们之前在操作系统中使用 sbi_call 一样，只需要符合规则传递参数即可。而且这一次我们甚至不需要参考任何标准，每个人都可以为自己的操作系统实现自己的标准。 例如，在实验指导中，系统调用的编号使用了 musl 中的编码和参数格式。但实际上，在实现操作系统的时候，编码和参数格式都可以随意调整，只要在用户程序中的调用和操作系统中的解释相符即可。 代码示例 // musl 中的 sys_read 调用格式 llvm_asm!(\"ecall\" : \"={x10}\" (/* 返回读取长度 */) : \"{x10}\" (/* 文件描述符 */), \"{x11}\" (/* 读取缓冲区 */), \"{x12}\" (/* 缓冲区长度 */), \"{x17}\" (/* sys_read 编号 63 */) :: ); // 一种可能的 sys_read 调用格式 llvm_asm!(\"ecall\" : \"={x10}\" (/* 现在的时间 */), \"={x11}\" (/* 今天的天气 */), \"={x12}\" (/* 读取一个字符 */) : \"{x20}\" (/* sys_read 编号 0x595_7ead */) :: ); 实验指导提供了第一种无趣的系统调用格式。 阻塞 vs 非阻塞 在常见操作系统中，一些延迟非常大的操作，例如文件读写、网络通讯，都可以使用异步接口来进行。但是为了实现更加简便，我们的读写系统调用都是阻塞的。在 sys_read 中，使用了 loop 来保证仅当成功读取字符时才返回。 此时，如果用户程序需要获取从控制台输入的字符，但是此时并没有任何字符到来。那么，程序将被阻塞，而操作系统的职责就是尽量减少线程执行无用阻塞占用 CPU 的时间，而是将这段时间分配给其他可以执行的线程。具体的做法，将会在后面条件变量的章节讲述。 操作系统中实现系统调用 在操作系统中，系统调用的实现和中断处理一样，有同样的入口，而针对不同的参数设置不同的处理流程。为了简化流程，我们不妨把系统调用的处理结果分为三类： 返回一个数值，程序继续执行 程序进入等待 程序将被终止 系统调用的处理流程 首先，从相应的寄存器中取出调用代号和参数 根据调用代号，进入不同的处理流程，得到处理结果 返回数值并继续执行： 返回值存放在 x10 寄存器，sepc += 4，继续此 context 的执行 程序进入等待 同样需要更新 x10 和 sepc，但是需要将当前线程标记为等待，切换其他线程来执行 程序终止 不需要考虑系统调用的返回，直接删除线程 具体的调用实现 那么具体该如何实现读 / 写系统调用呢？这里我们会利用文件的统一接口 INode，使用其中的 read_at() 和 write_at() 接口即可。下一节就将讲解如何处理文件描述符。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-6/guide/part-5.html":{"url":"docs/lab-6/guide/part-5.html","title":"处理文件描述符","keywords":"","body":"处理文件描述符 尽管很不像，但是在大多操作系统中，标准输入输出流 stdin 和 stdout 虽然叫做「流」，但它们都有文件的接口。我们同样也会将它们实现成为文件。 但是不用担心，作为文件的许多功能，stdin 和 stdout 都不会支持。我们只需要为其实现最简单的读写接口。 进程打开的文件 操作系统需要为进程维护一个进程打开的文件清单。其中，一定存在的是 stdin stdout 和 stderr。为了简便，我们只实现 stdin 和 stdout，它们的文件描述符数值分别为 0 和 1。 stdout 输出流最为简单：每当遇到系统调用时，直接将缓冲区中的字符通过 SBI 调用打印出去。 stdin 输入流较为复杂：每当遇到系统调用时，通过中断或轮询方式获取字符：如果有，就进一步获取；如果没有就等待。直到收到约定长度的字符串才返回。 外部中断 对于用户程序而言，外部输入是随时主动读取的数据。但是事实上外部输入通常时间短暂且不会等待，需要操作系统立即处理并缓冲下来，再等待程序进行读取。所以，每一个键盘按键对于操作系统而言都是一次短暂的中断。 而在之前的实验中操作系统不会因为一个按键就崩溃，是因为 OpenSBI 默认会关闭各种外部中断。但是现在我们需要将其打开，来接受按键信息。 os/src/interrupt/handler.rs /// 初始化中断处理 /// /// 把中断入口 `__interrupt` 写入 `stvec` 中，并且开启中断使能 pub fn init() { unsafe { extern \"C\" { /// `interrupt.asm` 中的中断入口 fn __interrupt(); } // 使用 Direct 模式，将中断入口设置为 `__interrupt` stvec::write(__interrupt as usize, stvec::TrapMode::Direct); // 开启外部中断使能 sie::set_sext(); // 在 OpenSBI 中开启外部中断 *PhysicalAddress(0x0c00_2080).deref_kernel() = 1 这里，我们需要按照 OpenSBI 的接口在指定的地址进行配置。好在这些地址都在文件系统映射的空间内，就不需要再为其单独建立内存映射了。开启中断使能后，任何一个按键都会导致程序进入 unimplemented! 的区域。 实现输入流 输入流则需要配有一个缓冲区，我们可以用 alloc::collections::VecDeque 来实现。在遇到键盘中断时，调用 sbi_call 来获取字符并加入到缓冲区中。当遇到系统调用 sys_read 时，再相应从缓冲区中取出一定数量的字符。 那么，如果遇到了 sys_read 系统调用，而缓冲区并没有数据可以读取，应该如何让线程进行等待，而又不浪费 CPU 资源呢？ var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-6/guide/part-6.html":{"url":"docs/lab-6/guide/part-6.html","title":"条件变量","keywords":"","body":"条件变量 条件变量（conditional variable）的常见接口是这样的： wait：当前线程开始等待这个条件变量 notify_one：让某一个等待此条件变量的线程继续运行 notify_all：让所有等待此变量的线程继续运行 条件变量和互斥锁的区别在于，互斥锁解铃还须系铃人，但条件变量可以由任何来源发出 notify 信号。同时，互斥锁的一次 lock 一定对应一次 unlock，但条件变量多次 notify 只能保证 wait 的线程执行次数不超过 notify 次数。 为输入流加入条件变量后，就可以使得调用 sys_read 的线程在等待期间保持休眠，不被调度器选中，消耗 CPU 资源。 调整调度器 为了继续沿用调度算法，不带来太多修改，我们为线程池单独设立一个「休眠区」，其中保存的线程与调度器互斥。当线程进入等待，就将它从调度器中取出，避免之后再被无用唤起。 os/src/process/processor.rs pub struct Processor { /// 当前正在执行的线程 current_thread: Option>, /// 线程调度器，记录活跃线程 scheduler: SchedulerImpl>, /// 保存休眠线程 sleeping_threads: HashSet>, } 实现条件变量 条件变量会被包含在输入流等涉及等待和唤起的结构中，而一个条件变量保存的就是所有等待它的线程。 os/src/kernel/condvar.rs #[derive(Default)] pub struct Condvar { /// 所有等待此条件变量的线程 watchers: Mutex>>, } 当一个线程调用 sys_read 而缓冲区为空时，就会将其加入条件变量的 watcher 中，同时在 Processor 中移出活跃线程。而当键盘中断到来，读取到字符时，就会将线程重新放回调度器中，准备下一次调用。 开放思考：如果多个线程同时等待输入流会怎么样？有什么解决方案吗？ var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-6/guide/summary.html":{"url":"docs/lab-6/guide/summary.html","title":"小结","keywords":"","body":"总结 这一章的实验指导中，我们成功单独生成 ELF 格式的用户程序，并打包进文件系统中；同时，从中读取，创建并运行用户进程；而为了可以让用户程序享受到操作系统的功能，我们使用系统调用为用户程序提供服务。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-1/practice.html":{"url":"docs/lab-1/practice.html","title":"实验一：中断","keywords":"","body":"实验一：中断 实验之前 阅读实验指导零和一，最好一步步跟着实现一遍。 checkout 到仓库中的 lab-1 分支，实验题将以此展开。 我们的实验题会提供一个基础的代码框架，以便于进行实验。如果你选择参考教程，自己编写操作系统，这个代码框架也可以用来进行对照。 实验题 --> 简述：在 rust_main 函数中，执行 ebreak 命令后至函数结束前，sp 寄存器的值是怎样变化的？ Click to show sp 首先减去一个 Context 的大小（入栈），然后原 sp 的值被保存到这个入栈的 Context 中。 执行 handle_interrupt 的过程中，随着局部变量的使用，编译器可能会自动加入一些出入栈操作。但无论如何，handle_interrupt 前后 sp 的值是一样的。 从 handle_interrupt 返回后，执行 __restore，在最后将保存的原 sp 值恢复。 回答：如果去掉 rust_main 后的 panic 会发生什么，为什么？ Click to show rust_main 返回后，程序并没有停止。rust_main 是在 entry.asm 中通过 jal 指令调用的，因此其执行完后会回到 entry.asm 中。但是，entry.asm 并没有在后面写任何指令，这意味着程序将接着向后执行内存中的任何指令。 我们可以通过 rust-objdump -d -S os/target/riscv64imac-unknown-none-elf/debug/os | less 来查看汇编代码，其中就能看到：_start 只有短短三条指令，而后面则放着许多 Rust 库中的函数。这些指令可能导致程序进入循环，或崩溃退出。 实验 如果程序访问不存在的地址，会得到 Exception::LoadFault。模仿捕获 ebreak 和时钟中断的方法，捕获 LoadFault（之后 panic 即可）。 Click to show 直接在 match 中添加一个 arm 即可。例如 Trap::Exception(Exception::LoadFault) => panic!() 在处理异常的过程中，如果程序想要非法访问的地址是 0x0，则打印 SUCCESS!。 Click to show 如果程序因无效访问内存造成异常，这个访问的地址会被存放在 stval 中，而它已经被我们作为参数传入 handle_interrupt 了，因此直接判断即可 添加或修改少量代码，使得运行时触发这个异常，并且打印出 SUCCESS!。 要求：不允许添加或修改任何 unsafe 代码 Click to show 解法 1：在 interrupt/handler.rs 的 breakpoint 函数中，将 context.sepc += 2 修改为 context.sepc = 0（则 sret 时程序会跳转到 0x0） 解法 2：去除 rust_main 中的 panic 语句，并在 entry.asm 的 jal rust_main 之后，添加一行读取 0x0 地址的指令（例如 jr x0 或 ld x1, (x0)） var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "},"docs/lab-2/practice.html":{"url":"docs/lab-2/practice.html","title":"实验二：内存分配","keywords":"","body":"实验二：内存分配 实验之前 阅读实验指导二。 checkout 到仓库中的 lab-2 分支，实验题将以此展开。 实验题 回答：我们在动态内存分配中实现了一个堆，它允许我们在内核代码中使用动态分配的内存，例如 Vec Box 等。那么，如果我们在实现这个堆的过程中使用 Vec 而不是 [u8]，会出现什么结果？ 无法编译？ 运行时错误？ 正常运行？ Click to show 都不会！程序会陷入一个循环：它需要在堆上分配空间，但是分配器又需要在堆上分配空间…… 实验 回答：algorithm/src/allocator 下有一个 Allocator trait，我们之前用它实现了物理页面分配。这个算法的时间和空间复杂度是什么？ Click to show 时间复杂度是 O(1)，空间复杂度是 O(n) 实现基于线段树的物理页面分配算法 挑战实验（选做） 在 memory/heap2.rs 中，提供了一个手动实现堆的方法。它使用 algorithm::VectorAllocator 作为其根本分配算法，而我们目前提供了一个非常简单的 bitmap 算法（而且只开了很小的空间）。请在 algorithm crate 中利用伙伴算法实现 VectorAllocator trait。 前面说到，堆的实现本身不能使用动态内存分配。有没有什么方法能够让堆本身也能够利用 Vec 来动态分配空间？ Click to show 堆所用到的最初一部分空间必须静态分配，而随着使用空间增加，增量的部分实际上可以用 Vec 等来实现。 var gitalk = new Gitalk({ clientID: \"5084c46751a4b2f7cd4d\", clientSecret: \"3904f62d33aef24f19480fedc836a48b31d532e9\", repo: \"rCore-Tutorial-deploy\", owner: \"rcore-os\", admin: [ \"chyyuu\", \"wangrunji0408\", \"xy-plus\", \"wyfcyx\", \"LyricZhao\", \"Tuyixiang\" ], id: location.pathname, distractionFreeMode: false }); gitalk.render(\"gitalk-container\"); "}}